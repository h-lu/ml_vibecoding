{"title":"5.3 过拟合的诅咒与正则化的解药","markdown":{"yaml":{"title":"5.3 过拟合的诅咒与正则化的解药"},"headingText":"非线性扩展与过拟合的风险","containsRefs":false,"markdown":"\n\n线性回归优雅而简单，但它有一个强大的前提假设：**变量间的关系是线性的**。如果现实世界的数据点并非沿着一条直线分布，而是呈现出某种曲线关系，那么线性回归模型就无法很好地捕捉这个趋势，这种情况我们称之为**欠拟合 (Underfitting)**。\n\n为了解决这个问题，一个自然的想法是使用更复杂的模型，比如**多项式回归 (Polynomial Regression)**，来拟合这些曲线。然而，这扇门一旦打开，我们就会遇到一个机器学习中更普遍、更危险的敌人：**过拟合 (Overfitting)**。\n\n\n多项式回归通过在线性模型中加入特征的更高阶项（如 $x^2, x^3$ 等）来创造非线性的拟合曲线。模型越复杂（多项式的阶数越高），拟合曲线就能变得越“扭曲”，从而能够穿过更多的训练数据点。\n\n但这种灵活性是一把双刃剑。请看下面这个我们精心设计的互动动画，它深刻地揭示了模型“学习能力”的边界。\n\n<iframe src=\"../assets/ch05/overfitting_polynomial_log_mse.html\"\n        width=\"100%\" height=\"800\" frameborder=\"0\"></iframe>\n\n*在这个动画中，我们从一个已知的、带有波浪形态的真实函数（绿色虚线）中，带有噪声地采样了仅仅20个训练数据点（蓝色圆点）。我们的目标是找到一条能最好地逼近绿色真实函数的曲线。*\n\n*请尝试拖动下方的“多项式阶数”滑块，或者点击“播放”按钮，来观察以下几点：*\n\n1.  **左图的变化**：观察红色的**拟合曲线**如何随着阶数的增加而变化。\n    *   **低阶（如1-3阶）**：曲线过于“僵硬”，无法捕捉数据的真实趋势。这是一种**欠拟合 (Underfitting)** 状态，就像一个不怎么学习的学生，连课本上的重点都抓不住。\n    *   **中阶（如4-7阶）**：曲线变得平滑，并且很好地贴合了数据的整体走势，聪明地忽略了那些随机的噪声点。这是一种**良好拟合 (Good Fit)**，是模型泛化能力的最佳体现。\n    *   **高阶（如10阶以上）**：这是一场灾难。为了穿过几乎每一个训练数据点，拟合曲线变得异常剧烈地波动。它不再学习数据的“信号”，而是开始记忆数据中的**“噪声”**。这就是典型的**过拟合 (Overfitting)**。\n\n2.  **右图的变化**：这张图是关键，它揭示了“模型之眼”与“上帝之眼”的区别。\n    *   **训练MSE（蓝线）**：随着模型阶数增加，拟合曲线对训练点的拟合越来越好，所以训练误差会**持续下降**，甚至趋近于0。这很容易理解，模型越复杂，记性就越好。\n    *   **测试MSE（橙线）**：这代表了模型在未知新数据上的表现。你会看到一条清晰的 **U形曲线**。在某个“最佳点”之前，测试误差随阶数增加而下降；但越过这个点之后，测试误差会因为模型过拟合而**急剧上升**。\n\n**过拟合的本质**：一个模型对训练数据拟合得“过于完美”，以至于它失去了**泛化 (Generalization)** 到未知新数据的能力。系统架构师的核心任务之一，就是使用各种工具和方法，在U形曲线的谷底，精准地找到那个泛化能力最强的“最佳模型”，而不是被训练误差的持续下降所迷惑。\n\n### 信息论视角：正则化是给“模型复杂度”的惩罚\n\n如何防止过拟合？我们需要一种方法来控制模型的复杂度。从信息论的角度看，一个过拟合的模型是一个“信息量过大”的模型，它试图用过于复杂的参数来“记住”训练数据的所有细节。\n\n**正则化 (Regularization)** 就是解决这个问题的良药。它的核心思想非常直观：**在我们的优化目标（即损失函数，如最小化残差平方和）后面，增加一个“惩罚项”，这个惩罚项专门用来惩罚模型的复杂度。**\n\n$$\n\\text{新目标} = \\underbrace{\\sum (y_i - \\hat{y}_i)^2}_{\\text{原始损失：模型要拟合数据}} + \\underbrace{\\lambda \\cdot \\text{Complexity}(w)}_{\\text{惩罚项：模型参数不能太复杂}}\n$$\n\n这里的 $w$ 代表模型的所有系数（权重），$\\text{Complexity}(w)$ 是一个衡量模型复杂度的函数，而 $\\lambda$（Lambda）是一个超参数，用来控制惩罚的力度。\n\n最常见的两种正则化方法是 Lasso 和 Ridge 回归，它们的区别仅在于如何定义“模型复杂度”。\n\n#### Lasso (L1 正则化): 实现特征选择\n\nLasso 回归使用的惩罚项是模型所有系数的**绝对值之和**。\n\n$$\n\\text{Lasso 惩罚} = \\lambda \\sum |w_j|\n$$\n\nL1 惩罚有一个非常重要的特性：它倾向于将那些**不那么重要**的特征的系数**直接惩罚到零**。这相当于模型在训练过程中自动帮你判断哪些特征是“噪声”并将其剔除。因此，Lasso 回归不仅可以防止过拟合，还能实现**自动的特征选择**，非常适用于特征数量庞大的场景。\n\n#### Ridge (L2 正则化): 让模型更平滑稳健\n\nRidge 回归使用的惩罚项是模型所有系数的**平方和**。\n\n$$\n\\text{Ridge 惩罚} = \\lambda \\sum w_j^2\n$$\n\nL2 惩罚倾向于让所有特征的系数都**变得更小**，但**不会完全变为零**。它通过“缩减”所有系数的量级，来降低模型对单个特征的依赖，从而使模型的整体表现更**平滑**、更**稳健**，对于数据中的小扰动不那么敏感。\n\n**总结一下：**\n-   **需要从大量特征中筛选出关键特征时**：优先考虑 **Lasso**。\n-   **当所有特征你认为都有用，但担心模型对数据过于敏感时**：优先考虑 **Ridge**。\n\n通过引入正则化，我们赋予了模型一种内在的“权衡”能力：在“努力拟合训练数据”和“保持自身简单性”之间找到一个最佳的平衡点。这正是从一个只会死记硬背的学生，成长为一个懂得举一反三、抓住问题本质的学者的关键一步。\n\n### Elastic Net：集大成者\n\n既然 Lasso 和 Ridge 各有优势，一个自然的问题是：我们能否同时拥有它们的好处？答案是肯定的，这就是**弹性网络 (Elastic Net)**。\n\nElastic Net 巧妙地将 L1 和 L2 两种惩罚项结合了起来：\n$$\n\\text{ElasticNet 惩罚} = \\lambda_1 \\sum |w_j| + \\lambda_2 \\sum w_j^2\n$$\n它通过两个参数来控制两种正则化的混合比例。\n\n**为什么要使用 Elastic Net？**\n它成为了许多场景下的首选，因为它解决了单独使用 Lasso 或 Ridge 的一些痛点：\n-   **处理高度相关的特征组**: 当数据中有一组特征彼此高度相关时（例如，“房屋面积”和“房间数量”），Lasso 可能会随机地只选择其中一个，而忽略其他。这可能导致模型不稳定。Elastic Net 因为有 Ridge 的 L2 惩罚部分，它会倾向于将这一组相关的特征**同时选中或同时排除**，得到的结果更符合业务直觉。\n-   **特征数远大于样本数时**: 在这种情况下（例如基因数据分析），Lasso 最多只能选择等同于样本数量的特征。Elastic Net 则没有这个限制。\n\n\n### 可视化对比：正则化如何驯服过拟合\n\n<iframe src=\"../assets/ch05/regularization_fixed15_paths.html\"\n        width=\"100%\" height=\"700\" frameborder=\"0\"></iframe>\n\n这个动画生动地展示了正则化的威力。我们固定使用一个容易过拟合的 **15 阶多项式模型**，然后观察三种不同的正则化方法是如何在不同的惩罚强度 $\\lambda$ 下，对拟合曲线、泛化误差和模型系数进行“驯服”的。\n\n**如何操作与观察**\n\n1.  **切换方法**：在 `Ridge`, `Lasso`, `Elastic Net` 之间切换，观察不同正则化策略的根本差异。\n2.  **观察当惩罚力度 `λ` 从小到大变化时：**\n    *   **左图（函数空间）**：橙色的拟合曲线如何从剧烈波动的**过拟合**状态，逐渐被“拉平”，变得越来越**平滑**。当 `λ` 过大时，曲线甚至会变得过于简单，造成**欠拟合**。\n    *   **中间（泛化误差）**：测试MSE（橙线）描绘出的 **U形曲线**。我们的目标就是找到这条曲线的谷底，即最佳的 `λ` 值。\n    *   **右侧（系数路径）**：观察15个模型系数的大小如何随着 `λ` 变化。\n        *   **Ridge**: 所有系数都被一致地向零**压缩**，但很少会精确地等于零。\n        *   **Lasso**: 许多系数被迅速地**压至零**，这体现了它的**稀疏性**和**特征选择**能力。\n        *   **Elastic Net**: 表现介于两者之间，既实现了系数的收缩，也实现了稀疏化。\n\n**教学要点**\n\n*   正则化通过在损失函数中加入“复杂度惩罚项”，迫使模型在**“拟合训练数据”**和**“保持自身简单性”**之间做出权衡。\n*   L1 正则化 (Lasso) 的惩罚形状（菱形）使其倾向于产生**稀疏解**（特征选择）。\n*   L2 正则化 (Ridge) 的惩罚形状（圆形）使其倾向于产生**平滑解**（系数收缩）。\n*   通过这个动画，我们能直观地理解，选择合适的正则化方法和调整超参数 `λ`，是控制模型复杂度、防止过拟合、提升泛化能力的关键步骤。\n\n**系统架构师的视角：**\n将 Lasso 和 Ridge 看作是工具箱里两把极端的工具：一把（Lasso）用于“大刀阔斧”地砍掉无用特征，另一把（Ridge）用于“精雕细琢”地让所有特征更协调。而 **Elastic Net 则是那把可以灵活调节的“多功能瑞士军刀”**。在不确定哪种方法更好的情况下，从 Elastic Net 开始往往是一个非常稳健的最佳实践。它体现了在复杂问题面前，寻找“平衡”与“权衡”的系统设计思想。\n","srcMarkdownNoYaml":"\n\n线性回归优雅而简单，但它有一个强大的前提假设：**变量间的关系是线性的**。如果现实世界的数据点并非沿着一条直线分布，而是呈现出某种曲线关系，那么线性回归模型就无法很好地捕捉这个趋势，这种情况我们称之为**欠拟合 (Underfitting)**。\n\n为了解决这个问题，一个自然的想法是使用更复杂的模型，比如**多项式回归 (Polynomial Regression)**，来拟合这些曲线。然而，这扇门一旦打开，我们就会遇到一个机器学习中更普遍、更危险的敌人：**过拟合 (Overfitting)**。\n\n### 非线性扩展与过拟合的风险\n\n多项式回归通过在线性模型中加入特征的更高阶项（如 $x^2, x^3$ 等）来创造非线性的拟合曲线。模型越复杂（多项式的阶数越高），拟合曲线就能变得越“扭曲”，从而能够穿过更多的训练数据点。\n\n但这种灵活性是一把双刃剑。请看下面这个我们精心设计的互动动画，它深刻地揭示了模型“学习能力”的边界。\n\n<iframe src=\"../assets/ch05/overfitting_polynomial_log_mse.html\"\n        width=\"100%\" height=\"800\" frameborder=\"0\"></iframe>\n\n*在这个动画中，我们从一个已知的、带有波浪形态的真实函数（绿色虚线）中，带有噪声地采样了仅仅20个训练数据点（蓝色圆点）。我们的目标是找到一条能最好地逼近绿色真实函数的曲线。*\n\n*请尝试拖动下方的“多项式阶数”滑块，或者点击“播放”按钮，来观察以下几点：*\n\n1.  **左图的变化**：观察红色的**拟合曲线**如何随着阶数的增加而变化。\n    *   **低阶（如1-3阶）**：曲线过于“僵硬”，无法捕捉数据的真实趋势。这是一种**欠拟合 (Underfitting)** 状态，就像一个不怎么学习的学生，连课本上的重点都抓不住。\n    *   **中阶（如4-7阶）**：曲线变得平滑，并且很好地贴合了数据的整体走势，聪明地忽略了那些随机的噪声点。这是一种**良好拟合 (Good Fit)**，是模型泛化能力的最佳体现。\n    *   **高阶（如10阶以上）**：这是一场灾难。为了穿过几乎每一个训练数据点，拟合曲线变得异常剧烈地波动。它不再学习数据的“信号”，而是开始记忆数据中的**“噪声”**。这就是典型的**过拟合 (Overfitting)**。\n\n2.  **右图的变化**：这张图是关键，它揭示了“模型之眼”与“上帝之眼”的区别。\n    *   **训练MSE（蓝线）**：随着模型阶数增加，拟合曲线对训练点的拟合越来越好，所以训练误差会**持续下降**，甚至趋近于0。这很容易理解，模型越复杂，记性就越好。\n    *   **测试MSE（橙线）**：这代表了模型在未知新数据上的表现。你会看到一条清晰的 **U形曲线**。在某个“最佳点”之前，测试误差随阶数增加而下降；但越过这个点之后，测试误差会因为模型过拟合而**急剧上升**。\n\n**过拟合的本质**：一个模型对训练数据拟合得“过于完美”，以至于它失去了**泛化 (Generalization)** 到未知新数据的能力。系统架构师的核心任务之一，就是使用各种工具和方法，在U形曲线的谷底，精准地找到那个泛化能力最强的“最佳模型”，而不是被训练误差的持续下降所迷惑。\n\n### 信息论视角：正则化是给“模型复杂度”的惩罚\n\n如何防止过拟合？我们需要一种方法来控制模型的复杂度。从信息论的角度看，一个过拟合的模型是一个“信息量过大”的模型，它试图用过于复杂的参数来“记住”训练数据的所有细节。\n\n**正则化 (Regularization)** 就是解决这个问题的良药。它的核心思想非常直观：**在我们的优化目标（即损失函数，如最小化残差平方和）后面，增加一个“惩罚项”，这个惩罚项专门用来惩罚模型的复杂度。**\n\n$$\n\\text{新目标} = \\underbrace{\\sum (y_i - \\hat{y}_i)^2}_{\\text{原始损失：模型要拟合数据}} + \\underbrace{\\lambda \\cdot \\text{Complexity}(w)}_{\\text{惩罚项：模型参数不能太复杂}}\n$$\n\n这里的 $w$ 代表模型的所有系数（权重），$\\text{Complexity}(w)$ 是一个衡量模型复杂度的函数，而 $\\lambda$（Lambda）是一个超参数，用来控制惩罚的力度。\n\n最常见的两种正则化方法是 Lasso 和 Ridge 回归，它们的区别仅在于如何定义“模型复杂度”。\n\n#### Lasso (L1 正则化): 实现特征选择\n\nLasso 回归使用的惩罚项是模型所有系数的**绝对值之和**。\n\n$$\n\\text{Lasso 惩罚} = \\lambda \\sum |w_j|\n$$\n\nL1 惩罚有一个非常重要的特性：它倾向于将那些**不那么重要**的特征的系数**直接惩罚到零**。这相当于模型在训练过程中自动帮你判断哪些特征是“噪声”并将其剔除。因此，Lasso 回归不仅可以防止过拟合，还能实现**自动的特征选择**，非常适用于特征数量庞大的场景。\n\n#### Ridge (L2 正则化): 让模型更平滑稳健\n\nRidge 回归使用的惩罚项是模型所有系数的**平方和**。\n\n$$\n\\text{Ridge 惩罚} = \\lambda \\sum w_j^2\n$$\n\nL2 惩罚倾向于让所有特征的系数都**变得更小**，但**不会完全变为零**。它通过“缩减”所有系数的量级，来降低模型对单个特征的依赖，从而使模型的整体表现更**平滑**、更**稳健**，对于数据中的小扰动不那么敏感。\n\n**总结一下：**\n-   **需要从大量特征中筛选出关键特征时**：优先考虑 **Lasso**。\n-   **当所有特征你认为都有用，但担心模型对数据过于敏感时**：优先考虑 **Ridge**。\n\n通过引入正则化，我们赋予了模型一种内在的“权衡”能力：在“努力拟合训练数据”和“保持自身简单性”之间找到一个最佳的平衡点。这正是从一个只会死记硬背的学生，成长为一个懂得举一反三、抓住问题本质的学者的关键一步。\n\n### Elastic Net：集大成者\n\n既然 Lasso 和 Ridge 各有优势，一个自然的问题是：我们能否同时拥有它们的好处？答案是肯定的，这就是**弹性网络 (Elastic Net)**。\n\nElastic Net 巧妙地将 L1 和 L2 两种惩罚项结合了起来：\n$$\n\\text{ElasticNet 惩罚} = \\lambda_1 \\sum |w_j| + \\lambda_2 \\sum w_j^2\n$$\n它通过两个参数来控制两种正则化的混合比例。\n\n**为什么要使用 Elastic Net？**\n它成为了许多场景下的首选，因为它解决了单独使用 Lasso 或 Ridge 的一些痛点：\n-   **处理高度相关的特征组**: 当数据中有一组特征彼此高度相关时（例如，“房屋面积”和“房间数量”），Lasso 可能会随机地只选择其中一个，而忽略其他。这可能导致模型不稳定。Elastic Net 因为有 Ridge 的 L2 惩罚部分，它会倾向于将这一组相关的特征**同时选中或同时排除**，得到的结果更符合业务直觉。\n-   **特征数远大于样本数时**: 在这种情况下（例如基因数据分析），Lasso 最多只能选择等同于样本数量的特征。Elastic Net 则没有这个限制。\n\n\n### 可视化对比：正则化如何驯服过拟合\n\n<iframe src=\"../assets/ch05/regularization_fixed15_paths.html\"\n        width=\"100%\" height=\"700\" frameborder=\"0\"></iframe>\n\n这个动画生动地展示了正则化的威力。我们固定使用一个容易过拟合的 **15 阶多项式模型**，然后观察三种不同的正则化方法是如何在不同的惩罚强度 $\\lambda$ 下，对拟合曲线、泛化误差和模型系数进行“驯服”的。\n\n**如何操作与观察**\n\n1.  **切换方法**：在 `Ridge`, `Lasso`, `Elastic Net` 之间切换，观察不同正则化策略的根本差异。\n2.  **观察当惩罚力度 `λ` 从小到大变化时：**\n    *   **左图（函数空间）**：橙色的拟合曲线如何从剧烈波动的**过拟合**状态，逐渐被“拉平”，变得越来越**平滑**。当 `λ` 过大时，曲线甚至会变得过于简单，造成**欠拟合**。\n    *   **中间（泛化误差）**：测试MSE（橙线）描绘出的 **U形曲线**。我们的目标就是找到这条曲线的谷底，即最佳的 `λ` 值。\n    *   **右侧（系数路径）**：观察15个模型系数的大小如何随着 `λ` 变化。\n        *   **Ridge**: 所有系数都被一致地向零**压缩**，但很少会精确地等于零。\n        *   **Lasso**: 许多系数被迅速地**压至零**，这体现了它的**稀疏性**和**特征选择**能力。\n        *   **Elastic Net**: 表现介于两者之间，既实现了系数的收缩，也实现了稀疏化。\n\n**教学要点**\n\n*   正则化通过在损失函数中加入“复杂度惩罚项”，迫使模型在**“拟合训练数据”**和**“保持自身简单性”**之间做出权衡。\n*   L1 正则化 (Lasso) 的惩罚形状（菱形）使其倾向于产生**稀疏解**（特征选择）。\n*   L2 正则化 (Ridge) 的惩罚形状（圆形）使其倾向于产生**平滑解**（系数收缩）。\n*   通过这个动画，我们能直观地理解，选择合适的正则化方法和调整超参数 `λ`，是控制模型复杂度、防止过拟合、提升泛化能力的关键步骤。\n\n**系统架构师的视角：**\n将 Lasso 和 Ridge 看作是工具箱里两把极端的工具：一把（Lasso）用于“大刀阔斧”地砍掉无用特征，另一把（Ridge）用于“精雕细琢”地让所有特征更协调。而 **Elastic Net 则是那把可以灵活调节的“多功能瑞士军刀”**。在不确定哪种方法更好的情况下，从 Elastic Net 开始往往是一个非常稳健的最佳实践。它体现了在复杂问题面前，寻找“平衡”与“权衡”的系统设计思想。\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../assets/sidebar-collapse.css"],"toc":false,"number-sections":false,"highlight-style":"github","include-in-header":{"text":"<link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n<link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap\" rel=\"stylesheet\">\n<style>\n/* ChatGPT 风格变量 */\n:root {\n  --chatgpt-primary: #000000;\n  --chatgpt-secondary: #6b7280;\n  --chatgpt-background: #ffffff;\n  --chatgpt-surface: #f7f7f8;\n  --chatgpt-border: #e5e5e5;\n  --chatgpt-accent: #10a37f;\n}\n</style>\n"},"include-after-body":{"text":"<script src=\"assets/sidebar-collapse.js\"></script>\n"},"output-file":"5_3_overfitting_regularization.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.14","theme":["cosmo","../assets/chatgpt-style.scss"],"fig-cap-location":"bottom","mainfont":"Inter, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Ubuntu, Cantarell, 'Noto Sans', sans-serif, 'Helvetica Neue', Arial, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'","monofont":"Monaco, 'SF Mono', 'Cascadia Code', 'Roboto Mono', Consolas, 'Courier New', monospace","fontsize":"16px","linestretch":1.6,"code-copy":true,"max-width":"1200px","title":"5.3 过拟合的诅咒与正则化的解药"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}