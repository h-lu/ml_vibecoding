{"title":"10.4 初探 Transformer 与注意力机制","markdown":{"yaml":{"title":"10.4 初探 Transformer 与注意力机制"},"headingText":"静态嵌入的局限性：一词多义问题","containsRefs":false,"markdown":"\n\n我们已经学习了如何通过 RAG 架构，让 LLM 具备了利用外部知识的能力。但是，LLM 自身是如何做到如此强大的语言理解和生成的呢？这就要归功于一个革命性的架构——**Transformer**，以及其最核心的灵魂——**注意力机制 (Attention Mechanism)**。\n\n在本节，我们的目标不是深入其复杂的数学实现，而是从第一性原理和直觉层面，理解注意力机制试图解决的根本问题是什么。\n\n\n我们之前学习的词嵌入技术（如 Word2Vec, GloVe）是**静态的 (Static)**。这意味着，无论一个词出现在什么上下文中，它的向量表示都是固定的。\n\n这带来了一个巨大的问题——**无法处理一词多义**。\n\n思考下面两个句子：\n\n1.  I went to the **bank** to deposit money. (我去了**银行**存钱。)\n2.  The river **bank** was muddy. (**河岸**很泥泞。)\n\n在这两个句子中，“bank”的含义截然不同。但是，对于一个静态的词嵌入模型来说，它只有一个固定的 `vector('bank')`。模型无法根据上下文来动态地调整这个向量，以区分“银行”和“河岸”这两个概念。这极大地限制了模型对语言细微差别的理解能力。\n\n为了让模型能真正像人类一样理解上下文，我们需要一种新的机制，让词语的表示能够**动态地 (Dynamically)** 根据其所处的句子环境而改变。\n\n### 注意力机制的直觉\n\n让我们先思考一下，我们人类是如何理解语言的。当我们阅读下面这个句子时：\n\n> \"The animal didn't cross the street because **it** was too tired.\"\n> (这只动物没有过马路，因为它太累了。)\n\n我们的大脑会毫不费力地理解，代词 **\"it\"** 指的是 **\"animal\"**，而不是 \"street\"。在这个理解过程中，我们的大脑其实在进行一个下意识的“注意力分配”：当处理 \"it\" 这个词时，我们会给予 \"animal\" 这个词**更高**的注意力权重，而给予 \"street\" 等其他词**较低**的注意力权重。\n\n**注意力机制 (Attention Mechanism)** 正是这种人类认知过程的数学模拟。\n\n其核心思想是：当模型在处理句子中的某一个词时（例如，在翻译或生成下一个词时），它不应该平等地看待句子中的所有其他词。相反，它应该**学会去“关注”那些与当前任务最相关的词**，并赋予它们更高的权重，然后将这些加权后的信息，融入到当前词的表示中。\n\n![Attention Mechanism](https://jalammar.github.io/images/t/transformer_self-attention_visualization.png)\n\n*图片来源: \"[The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\" by Jay Alammar*\n\n在上图中，当模型在生成 \"it\" 的法语翻译时，它的“注意力”高度集中在了 \"The animal\" 上，从而能够正确地生成法语中对应阳性形式的代词。\n\n### Transformer：注意力就是你所需要的全部\n\n在 Transformer 架构出现之前，处理序列数据（如文本）的主流模型是循环神经网络 (RNN) 和长短期记忆网络 (LSTM)。它们通过一个接一个地处理词语来试图捕捉序列信息，但存在梯度消失和难以并行计算等问题。\n\n2017年，一篇名为《Attention Is All You Need》的论文横空出世，提出了 **Transformer** 模型。其革命性在于，它**完全抛弃了传统的循环结构，完全基于注意力机制**来捕捉文本中的依赖关系。\n\n通过一种被称为**自注意力 (Self-Attention)** 的机制，模型在处理句子中的每一个词时，都会计算句子中所有其他词对它自己的“注意力分数”。这使得模型能够同时捕捉到一个句子内部任意两个词之间的长距离依赖关系，而无需像 RNN 那样逐步传递信息。\n\n这种架构不仅在效果上取得了巨大突破，而且由于其高度可并行的特性，使得在海量数据上训练超大规模模型（即我们今天所说的 LLM）成为了可能。\n\n\n在本章，我们只需要对注意力机制建立起上述的**直觉性理解**。你只需要记住：**注意力机制是一种让模型能够根据上下文，动态地聚焦于关键信息的技术**。\n\n在后续的第十一章中，我们将更深入地拆解 Transformer 的内部结构和自注意力机制的计算细节，真正揭开现代 LLM 的核心奥秘。\n","srcMarkdownNoYaml":"\n\n我们已经学习了如何通过 RAG 架构，让 LLM 具备了利用外部知识的能力。但是，LLM 自身是如何做到如此强大的语言理解和生成的呢？这就要归功于一个革命性的架构——**Transformer**，以及其最核心的灵魂——**注意力机制 (Attention Mechanism)**。\n\n在本节，我们的目标不是深入其复杂的数学实现，而是从第一性原理和直觉层面，理解注意力机制试图解决的根本问题是什么。\n\n### 静态嵌入的局限性：一词多义问题\n\n我们之前学习的词嵌入技术（如 Word2Vec, GloVe）是**静态的 (Static)**。这意味着，无论一个词出现在什么上下文中，它的向量表示都是固定的。\n\n这带来了一个巨大的问题——**无法处理一词多义**。\n\n思考下面两个句子：\n\n1.  I went to the **bank** to deposit money. (我去了**银行**存钱。)\n2.  The river **bank** was muddy. (**河岸**很泥泞。)\n\n在这两个句子中，“bank”的含义截然不同。但是，对于一个静态的词嵌入模型来说，它只有一个固定的 `vector('bank')`。模型无法根据上下文来动态地调整这个向量，以区分“银行”和“河岸”这两个概念。这极大地限制了模型对语言细微差别的理解能力。\n\n为了让模型能真正像人类一样理解上下文，我们需要一种新的机制，让词语的表示能够**动态地 (Dynamically)** 根据其所处的句子环境而改变。\n\n### 注意力机制的直觉\n\n让我们先思考一下，我们人类是如何理解语言的。当我们阅读下面这个句子时：\n\n> \"The animal didn't cross the street because **it** was too tired.\"\n> (这只动物没有过马路，因为它太累了。)\n\n我们的大脑会毫不费力地理解，代词 **\"it\"** 指的是 **\"animal\"**，而不是 \"street\"。在这个理解过程中，我们的大脑其实在进行一个下意识的“注意力分配”：当处理 \"it\" 这个词时，我们会给予 \"animal\" 这个词**更高**的注意力权重，而给予 \"street\" 等其他词**较低**的注意力权重。\n\n**注意力机制 (Attention Mechanism)** 正是这种人类认知过程的数学模拟。\n\n其核心思想是：当模型在处理句子中的某一个词时（例如，在翻译或生成下一个词时），它不应该平等地看待句子中的所有其他词。相反，它应该**学会去“关注”那些与当前任务最相关的词**，并赋予它们更高的权重，然后将这些加权后的信息，融入到当前词的表示中。\n\n![Attention Mechanism](https://jalammar.github.io/images/t/transformer_self-attention_visualization.png)\n\n*图片来源: \"[The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\" by Jay Alammar*\n\n在上图中，当模型在生成 \"it\" 的法语翻译时，它的“注意力”高度集中在了 \"The animal\" 上，从而能够正确地生成法语中对应阳性形式的代词。\n\n### Transformer：注意力就是你所需要的全部\n\n在 Transformer 架构出现之前，处理序列数据（如文本）的主流模型是循环神经网络 (RNN) 和长短期记忆网络 (LSTM)。它们通过一个接一个地处理词语来试图捕捉序列信息，但存在梯度消失和难以并行计算等问题。\n\n2017年，一篇名为《Attention Is All You Need》的论文横空出世，提出了 **Transformer** 模型。其革命性在于，它**完全抛弃了传统的循环结构，完全基于注意力机制**来捕捉文本中的依赖关系。\n\n通过一种被称为**自注意力 (Self-Attention)** 的机制，模型在处理句子中的每一个词时，都会计算句子中所有其他词对它自己的“注意力分数”。这使得模型能够同时捕捉到一个句子内部任意两个词之间的长距离依赖关系，而无需像 RNN 那样逐步传递信息。\n\n这种架构不仅在效果上取得了巨大突破，而且由于其高度可并行的特性，使得在海量数据上训练超大规模模型（即我们今天所说的 LLM）成为了可能。\n\n\n在本章，我们只需要对注意力机制建立起上述的**直觉性理解**。你只需要记住：**注意力机制是一种让模型能够根据上下文，动态地聚焦于关键信息的技术**。\n\n在后续的第十一章中，我们将更深入地拆解 Transformer 的内部结构和自注意力机制的计算细节，真正揭开现代 LLM 的核心奥秘。\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":false,"number-sections":false,"highlight-style":"github","include-in-header":{"text":"<link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n<link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap\" rel=\"stylesheet\">\n<style>\n/* ChatGPT 风格变量 */\n:root {\n  --chatgpt-primary: #000000;\n  --chatgpt-secondary: #6b7280;\n  --chatgpt-background: #ffffff;\n  --chatgpt-surface: #f7f7f8;\n  --chatgpt-border: #e5e5e5;\n  --chatgpt-accent: #10a37f;\n}\n</style>\n"},"output-file":"10_4_transformer_attention.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.14","theme":["cosmo","../assets/chatgpt-style.scss"],"fig-cap-location":"bottom","mainfont":"Inter, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Ubuntu, Cantarell, 'Noto Sans', sans-serif, 'Helvetica Neue', Arial, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'","monofont":"Monaco, 'SF Mono', 'Cascadia Code', 'Roboto Mono', Consolas, 'Courier New', monospace","fontsize":"16px","linestretch":1.6,"code-copy":true,"max-width":"1200px","mermaid":{"theme":"neutral","config":{"themeVariables":{"fontFamily":"\"Helvetica Neue\", Helvetica, Arial, sans-serif","primaryColor":"#2F5597","primaryBorderColor":"#1F4E79","secondaryColor":"#A5A5A5","tertiaryColor":"#FAF3E0","lineColor":"#555555"}}},"title":"10.4 初探 Transformer 与注意力机制"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}