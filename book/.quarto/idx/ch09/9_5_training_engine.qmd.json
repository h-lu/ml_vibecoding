{"title":"9.5 训练的引擎：反向传播与梯度下降","markdown":{"yaml":{"title":"9.5 训练的引擎：反向传播与梯度下降"},"headingText":"第一步：定义“好”与“坏”——损失函数 (Loss Function)","containsRefs":false,"markdown":"\n\n我们已经组装好了一个拥有成千上万个参数（权重 $w$ 和偏置 $b$）的网络。在刚开始时，这些参数都是随机初始化的。因此，这个未经训练的网络，就像一个什么都不懂的“婴儿”，对于任何输入，它只会输出一堆随机的、毫无意义的预测。\n\n**“训练”这个过程，本质上就是寻找一套“正确”的参数，使得网络能够对给定的输入，产生我们期望的输出。**\n\n这个寻找过程，就像是在一个极其辽阔、崎岖不平的山脉中，蒙着眼睛寻找最低的山谷。而驱动我们下山的引擎，正是由**损失函数**、**梯度下降**和**反向传播**这三大核心部件构成的。\n\n\n我们需要一个明确的指标，来量化网络当前预测的“糟糕程度”。这个指标，就是**损失函数 (Loss Function)**，有时也叫**成本函数 (Cost Function)** 或**目标函数 (Objective Function)**。\n\n损失函数会比较网络当前的预测值和真实的标签值，然后计算出一个数值——“损失值”。\n\n-   **损失值越大**，说明网络的预测越离谱，离正确答案越远。\n-   **损失值越小**，说明网络的预测越准确。\n-   **训练的目标**，就是通过调整网络的参数，让这个损失值变得尽可能小。\n\n常见的损失函数包括：\n\n-   **均方误差 (Mean Squared Error, MSE)**：常用于回归任务。\n-   **交叉熵 (Cross-Entropy)**：常用于分类任务。\n\n### 第二步：找到下山的方向——梯度下降 (Gradient Descent)\n\n现在我们有了一个可以衡量“糟糕程度”的损失值。你可以把这个损失值想象成我们在山脉中所处位置的“海拔”。我们的目标，是找到“海拔”最低的点。\n\n那么，我们该朝哪个方向走，才能让“海拔”下降得最快呢？\n\n在数学中，**梯度 (Gradient)** 正是指向一个函数值增长最快的方向的向量。因此，**梯度的反方向，就是函数值下降最快的方向。**\n\n**梯度下降 (Gradient Descent, GD)** 算法的核心思想非常直观：\n\n1.  在当前位置（即当前这组参数），计算损失函数关于每一个参数的梯度。\n2.  沿着梯度的**反方向**，迈出一小步，来更新每一个参数。\n3.  重复以上过程，直到损失值收敛到一个足够小的数值，或者达到预设的训练次数。\n\n<div class=\"quarto-figure quarto-figure-center\">\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f4/Gradient_descent.gif\" class=\"img-fluid\" alt=\"梯度下降\" width=\"400\">\n<figcaption>梯度下降的可视化。算法不断地沿着梯度的反方向更新参数，以寻找损失函数的最小值。(图片来源: Wikimedia Commons)</figcaption>\n</div>\n\n其中，“步子”的大小，由一个非常重要的超参数——**学习率 (Learning Rate)** 来控制。\n\n-   **学习率太大**：可能会导致我们在最低点附近“反复横跳”，甚至越过最低点，导致损失值不降反升。\n-   **学习率太小**：下山的速度会非常缓慢，需要极长的训练时间。\n\n### 第三步：高效的“责任分配”——反向传播 (Backpropagation)\n\n梯度下降告诉了我们**如何**更新参数（沿着梯度反方向），但还有一个关键问题没有解决：对于一个拥有数百万参数的深度网络，我们**如何高效地计算**出损失函数关于**每一个**参数的梯度？\n\n如果用最朴素的方法，为每个参数都单独计算一次梯度，那计算量将是天文数字。\n\n**反向传播 (Backpropagation, BP)** 算法，正是解决这个问题的天才发明。它利用了微积分中的**链式法则 (Chain Rule)**，实现了一种极其高效的梯度计算方式。\n\n其核心思想是：\n\n1.  **前向传播**：首先，让数据通过网络，计算出每一层的输出，直到最终的预测值。然后，用损失函数计算出总损失。\n2.  **反向传播**：从网络的**末端**（损失函数）开始，将“误差”或“责任”逐层地向**前**传播。\n    -   首先计算损失对输出层参数的梯度。\n    -   然后，利用链式法则，根据输出层的梯度，去计算倒数第二层参数的梯度。\n    -   ……\n    -   这个过程就像一个“责任分配”系统，它将最终的总误差，精确地、高效地分配给每一个对这个误差“负有责任”的参数（连接权重）。\n\n通过一次前向传播和一次反向传播，我们就能计算出损失函数关于网络中**所有参数**的梯度。这个效率，是深度学习能够成为现实的关键。\n\n### 第四步：选择更好的“交通工具”——优化器 (Optimizer)\n\n朴素的梯度下降（也称**随机梯度下降 (Stochastic Gradient Descent, SGD)**，在实际中我们每次只用一小批数据而不是全部数据来计算梯度）虽然有效，但它就像一个最基础的“步行”工具，有时会走得很慢，或者在复杂的山路中迷路（例如，卡在局部最小值或鞍点）。\n\n为了更快、更稳定地“下山”，研究者们发明了许多更先进的**优化器 (Optimizer)**，它们是对基础梯度下降算法的改进。\n\n::: {.callout-note title=\"架构师视角：优化器的选择\"}\n作为架构师，你不需要从头实现这些优化器，但你需要知道它们的核心思想和适用场景。\n\n-   **SGD with Momentum**：在 SGD 的基础上，引入了“动量”的概念。它不仅仅考虑当前梯度的方向，还会累积过去梯度的方向，就像一个从山上滚下来的小球，它会带着惯性冲过一些小的颠簸和平地，从而加速收敛并有助于跳出局部最小值。\n\n-   **Adam (Adaptive Moment Estimation)**：**这是当今深度学习领域最常用、也是通常情况下的默认首选优化器。** Adam 的强大之处在于，它将两种先进的思想集于一身：\n    1.  **动量 (Momentum)**：它像 SGD with Momentum 一样，使用梯度的**一阶矩估计**（可以理解为梯度的平均值）来保持前进的“惯性”。\n    2.  **自适应学习率 (Adaptive Learning Rate)**：它还为网络中的**每一个参数**，都独立地维护一个自适应的学习率。这是通过计算梯度的**二阶矩估计**（可以理解为梯度的方差）来实现的。对于梯度比较平缓（方差小）的参数，它会使用较大的学习率；对于梯度陡峭（方差大）的参数，它会使用较小的学习率，从而实现更精细、更稳定的更新。\n\n**为什么 Adam 是首选？** 因为它的自适应特性，使得它在大多数情况下都表现得非常鲁棒，对学习率的初始选择也不像 SGD 那样敏感。对于一个新项目，使用 Adam 和它的默认参数，通常能让你快速得到一个不错的结果。其他更高级的优化器（如 AdamW, RAdam, Lookahead 等）是在 Adam 基础上的进一步改进，可以在需要极致性能调优时考虑。\n:::\n\n至此，我们已经拥有了驱动神经网络学习所需的全套引擎。整个训练过程可以总结为一个循环：\n\n1.  取一小批数据进行**前向传播**，得到预测结果。\n2.  用**损失函数**计算预测与真实标签之间的误差。\n3.  通过**反向传播**，高效地计算出损失关于全部参数的梯度。\n4.  使用**优化器**（如 Adam），根据计算出的梯度，来更新网络的所有参数。\n5.  不断重复这个循环，直到网络的损失不再下降。\n","srcMarkdownNoYaml":"\n\n我们已经组装好了一个拥有成千上万个参数（权重 $w$ 和偏置 $b$）的网络。在刚开始时，这些参数都是随机初始化的。因此，这个未经训练的网络，就像一个什么都不懂的“婴儿”，对于任何输入，它只会输出一堆随机的、毫无意义的预测。\n\n**“训练”这个过程，本质上就是寻找一套“正确”的参数，使得网络能够对给定的输入，产生我们期望的输出。**\n\n这个寻找过程，就像是在一个极其辽阔、崎岖不平的山脉中，蒙着眼睛寻找最低的山谷。而驱动我们下山的引擎，正是由**损失函数**、**梯度下降**和**反向传播**这三大核心部件构成的。\n\n### 第一步：定义“好”与“坏”——损失函数 (Loss Function)\n\n我们需要一个明确的指标，来量化网络当前预测的“糟糕程度”。这个指标，就是**损失函数 (Loss Function)**，有时也叫**成本函数 (Cost Function)** 或**目标函数 (Objective Function)**。\n\n损失函数会比较网络当前的预测值和真实的标签值，然后计算出一个数值——“损失值”。\n\n-   **损失值越大**，说明网络的预测越离谱，离正确答案越远。\n-   **损失值越小**，说明网络的预测越准确。\n-   **训练的目标**，就是通过调整网络的参数，让这个损失值变得尽可能小。\n\n常见的损失函数包括：\n\n-   **均方误差 (Mean Squared Error, MSE)**：常用于回归任务。\n-   **交叉熵 (Cross-Entropy)**：常用于分类任务。\n\n### 第二步：找到下山的方向——梯度下降 (Gradient Descent)\n\n现在我们有了一个可以衡量“糟糕程度”的损失值。你可以把这个损失值想象成我们在山脉中所处位置的“海拔”。我们的目标，是找到“海拔”最低的点。\n\n那么，我们该朝哪个方向走，才能让“海拔”下降得最快呢？\n\n在数学中，**梯度 (Gradient)** 正是指向一个函数值增长最快的方向的向量。因此，**梯度的反方向，就是函数值下降最快的方向。**\n\n**梯度下降 (Gradient Descent, GD)** 算法的核心思想非常直观：\n\n1.  在当前位置（即当前这组参数），计算损失函数关于每一个参数的梯度。\n2.  沿着梯度的**反方向**，迈出一小步，来更新每一个参数。\n3.  重复以上过程，直到损失值收敛到一个足够小的数值，或者达到预设的训练次数。\n\n<div class=\"quarto-figure quarto-figure-center\">\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f4/Gradient_descent.gif\" class=\"img-fluid\" alt=\"梯度下降\" width=\"400\">\n<figcaption>梯度下降的可视化。算法不断地沿着梯度的反方向更新参数，以寻找损失函数的最小值。(图片来源: Wikimedia Commons)</figcaption>\n</div>\n\n其中，“步子”的大小，由一个非常重要的超参数——**学习率 (Learning Rate)** 来控制。\n\n-   **学习率太大**：可能会导致我们在最低点附近“反复横跳”，甚至越过最低点，导致损失值不降反升。\n-   **学习率太小**：下山的速度会非常缓慢，需要极长的训练时间。\n\n### 第三步：高效的“责任分配”——反向传播 (Backpropagation)\n\n梯度下降告诉了我们**如何**更新参数（沿着梯度反方向），但还有一个关键问题没有解决：对于一个拥有数百万参数的深度网络，我们**如何高效地计算**出损失函数关于**每一个**参数的梯度？\n\n如果用最朴素的方法，为每个参数都单独计算一次梯度，那计算量将是天文数字。\n\n**反向传播 (Backpropagation, BP)** 算法，正是解决这个问题的天才发明。它利用了微积分中的**链式法则 (Chain Rule)**，实现了一种极其高效的梯度计算方式。\n\n其核心思想是：\n\n1.  **前向传播**：首先，让数据通过网络，计算出每一层的输出，直到最终的预测值。然后，用损失函数计算出总损失。\n2.  **反向传播**：从网络的**末端**（损失函数）开始，将“误差”或“责任”逐层地向**前**传播。\n    -   首先计算损失对输出层参数的梯度。\n    -   然后，利用链式法则，根据输出层的梯度，去计算倒数第二层参数的梯度。\n    -   ……\n    -   这个过程就像一个“责任分配”系统，它将最终的总误差，精确地、高效地分配给每一个对这个误差“负有责任”的参数（连接权重）。\n\n通过一次前向传播和一次反向传播，我们就能计算出损失函数关于网络中**所有参数**的梯度。这个效率，是深度学习能够成为现实的关键。\n\n### 第四步：选择更好的“交通工具”——优化器 (Optimizer)\n\n朴素的梯度下降（也称**随机梯度下降 (Stochastic Gradient Descent, SGD)**，在实际中我们每次只用一小批数据而不是全部数据来计算梯度）虽然有效，但它就像一个最基础的“步行”工具，有时会走得很慢，或者在复杂的山路中迷路（例如，卡在局部最小值或鞍点）。\n\n为了更快、更稳定地“下山”，研究者们发明了许多更先进的**优化器 (Optimizer)**，它们是对基础梯度下降算法的改进。\n\n::: {.callout-note title=\"架构师视角：优化器的选择\"}\n作为架构师，你不需要从头实现这些优化器，但你需要知道它们的核心思想和适用场景。\n\n-   **SGD with Momentum**：在 SGD 的基础上，引入了“动量”的概念。它不仅仅考虑当前梯度的方向，还会累积过去梯度的方向，就像一个从山上滚下来的小球，它会带着惯性冲过一些小的颠簸和平地，从而加速收敛并有助于跳出局部最小值。\n\n-   **Adam (Adaptive Moment Estimation)**：**这是当今深度学习领域最常用、也是通常情况下的默认首选优化器。** Adam 的强大之处在于，它将两种先进的思想集于一身：\n    1.  **动量 (Momentum)**：它像 SGD with Momentum 一样，使用梯度的**一阶矩估计**（可以理解为梯度的平均值）来保持前进的“惯性”。\n    2.  **自适应学习率 (Adaptive Learning Rate)**：它还为网络中的**每一个参数**，都独立地维护一个自适应的学习率。这是通过计算梯度的**二阶矩估计**（可以理解为梯度的方差）来实现的。对于梯度比较平缓（方差小）的参数，它会使用较大的学习率；对于梯度陡峭（方差大）的参数，它会使用较小的学习率，从而实现更精细、更稳定的更新。\n\n**为什么 Adam 是首选？** 因为它的自适应特性，使得它在大多数情况下都表现得非常鲁棒，对学习率的初始选择也不像 SGD 那样敏感。对于一个新项目，使用 Adam 和它的默认参数，通常能让你快速得到一个不错的结果。其他更高级的优化器（如 AdamW, RAdam, Lookahead 等）是在 Adam 基础上的进一步改进，可以在需要极致性能调优时考虑。\n:::\n\n至此，我们已经拥有了驱动神经网络学习所需的全套引擎。整个训练过程可以总结为一个循环：\n\n1.  取一小批数据进行**前向传播**，得到预测结果。\n2.  用**损失函数**计算预测与真实标签之间的误差。\n3.  通过**反向传播**，高效地计算出损失关于全部参数的梯度。\n4.  使用**优化器**（如 Adam），根据计算出的梯度，来更新网络的所有参数。\n5.  不断重复这个循环，直到网络的损失不再下降。\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":false,"number-sections":false,"highlight-style":"github","include-in-header":{"text":"<link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n<link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap\" rel=\"stylesheet\">\n<style>\n/* ChatGPT 风格变量 */\n:root {\n  --chatgpt-primary: #000000;\n  --chatgpt-secondary: #6b7280;\n  --chatgpt-background: #ffffff;\n  --chatgpt-surface: #f7f7f8;\n  --chatgpt-border: #e5e5e5;\n  --chatgpt-accent: #10a37f;\n}\n</style>\n"},"output-file":"9_5_training_engine.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.14","theme":["cosmo","../assets/chatgpt-style.scss"],"fig-cap-location":"bottom","mainfont":"Inter, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Ubuntu, Cantarell, 'Noto Sans', sans-serif, 'Helvetica Neue', Arial, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'","monofont":"Monaco, 'SF Mono', 'Cascadia Code', 'Roboto Mono', Consolas, 'Courier New', monospace","fontsize":"16px","linestretch":1.6,"code-copy":true,"max-width":"1200px","title":"9.5 训练的引擎：反向传播与梯度下降"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}