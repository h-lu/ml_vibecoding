---
title: "16.3 å¯¹é½çš„ä¸‰å¤§è·¯å¾„ï¼šRM, DPO, ä¸ AI åé¦ˆ"
---

å°†äººç±»åå¥½æ³¨å…¥ AI æ¨¡å‹ï¼Œåœ¨ 2025 å¹´ï¼Œä¸šç•Œå·²ç»æ¢ç´¢å‡ºäº†ä¸‰æ¡ä¸»æµçš„æŠ€æœ¯è·¯å¾„ã€‚ä½œä¸ºç³»ç»Ÿæ¶æ„å¸ˆï¼Œç†è§£å®ƒä»¬çš„åŸç†ã€ä¼˜åŠ£å’Œé€‚ç”¨åœºæ™¯ï¼Œæ˜¯åšå‡ºæ­£ç¡®æŠ€æœ¯é€‰å‹çš„åŸºç¡€ã€‚

### è·¯å¾„ä¸€ï¼šå¥–åŠ±å»ºæ¨¡ (RM) + PPO (ç»å…¸èŒƒå¼)

è¿™æ˜¯æœ€æ—©æˆåŠŸå®ç°å¹¶è¢«å¹¿æ³›åº”ç”¨çš„èŒƒå¼ï¼Œä»¥ OpenAI çš„ **InstructGPT** å’Œåˆä»£ **ChatGPT** ä¸ºä»£è¡¨ï¼Œé€šå¸¸è¢«ç§°ä¸º **RLHF (Reinforcement Learning from Human Feedback)** çš„ç»å…¸æµç¨‹ã€‚

å®ƒæ˜¯ä¸€ä¸ªå¤æ‚çš„ã€åˆ†ä¸ºä¸¤æ­¥èµ°çš„ç³»ç»Ÿï¼š

1.  **ç¬¬ä¸€æ­¥ï¼šè®­ç»ƒä¸€ä¸ªâ€œå“å‘³è£åˆ¤â€**
    -   æˆ‘ä»¬é¦–å…ˆæ”¶é›†å¤§é‡çš„äººç±»åå¥½æ•°æ®ï¼Œæ¯ä¸€æ¡æ•°æ®éƒ½æ˜¯ä¸€ä¸ª `(prompt, chosen_response, rejected_response)` çš„ä¸‰å…ƒç»„ã€‚
    -   ç„¶åï¼Œæˆ‘ä»¬ç”¨è¿™äº›æ•°æ®ä¸“é—¨è®­ç»ƒä¸€ä¸ªç‹¬ç«‹çš„æ¨¡å‹ï¼Œç§°ä¸º**å¥–åŠ±æ¨¡å‹ (Reward Model, RM)**ã€‚è¿™ä¸ªæ¨¡å‹çš„ä»»åŠ¡å¾ˆç®€å•ï¼šè¾“å…¥ä¸€ä¸ª `(prompt, response)` å¯¹ï¼Œè¾“å‡ºä¸€ä¸ªåˆ†æ•°ï¼Œè¿™ä¸ªåˆ†æ•°ä»£è¡¨äº†äººç±»æœ‰å¤šå–œæ¬¢è¿™ä¸ª responseã€‚è®­ç»ƒçš„ç›®æ ‡ï¼Œå°±æ˜¯è®© chosen_response çš„å¾—åˆ†æ°¸è¿œé«˜äº rejected_response çš„å¾—åˆ†ã€‚

2.  **ç¬¬äºŒæ­¥ï¼šè®©æ¨¡å‹â€œåˆ·åˆ†â€**
    -   ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªå¯ä»¥è‡ªåŠ¨æ‰“åˆ†çš„â€œå“å‘³è£åˆ¤â€ï¼ˆå¥–åŠ±æ¨¡å‹ï¼‰ã€‚
    -   æˆ‘ä»¬è®©éœ€è¦è¢«å¯¹é½çš„è¯­è¨€æ¨¡å‹ï¼ˆé€šå¸¸ç§°ä¸ºâ€œç­–ç•¥æ¨¡å‹â€ï¼‰ä¸æ–­åœ°é’ˆå¯¹å„ç§ prompt ç”Ÿæˆæ–°çš„ç­”æ¡ˆã€‚
    -   æ¯ç”Ÿæˆä¸€ä¸ªç­”æ¡ˆï¼Œå°±ç«‹åˆ»äº¤ç»™â€œå“å‘³è£åˆ¤â€æ‰“åˆ†ã€‚
    -   æœ€åï¼Œä½¿ç”¨ä¸€ç§åä¸º**è¿‘ç«¯ç­–ç•¥ä¼˜åŒ– (Proximal Policy Optimization, PPO)** çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œæ ¹æ®è£åˆ¤ç»™å‡ºçš„åˆ†æ•°ï¼Œæ¥æ›´æ–°ç­–ç•¥æ¨¡å‹çš„å‚æ•°ã€‚æ•´ä¸ªè¿‡ç¨‹å°±åƒä¸€ä¸ªå­¦ç”Ÿä¸æ–­åœ°å†™ä½œä¸šï¼Œç„¶åç”±è€å¸ˆï¼ˆå¥–åŠ±æ¨¡å‹ï¼‰æ‰¹æ”¹ï¼Œå­¦ç”Ÿå†æ ¹æ®åˆ†æ•°é«˜ä½æ¥è°ƒæ•´è‡ªå·±çš„å­¦ä¹ ç­–ç•¥ã€‚

-   **ä¼˜ç‚¹**ï¼šéå¸¸çµæ´»ã€‚å¥–åŠ±æ¨¡å‹ä¸€æ—¦è®­ç»ƒå¥½ï¼Œå¯ä»¥ä½œä¸ºä¸€ä¸ªç‹¬ç«‹çš„â€œå“å‘³è¯„ä¼°å™¨â€ï¼Œç”¨äºè¯„ä¼°å’Œå¯¹é½å¤šä¸ªä¸åŒçš„ç­–ç•¥æ¨¡å‹ã€‚
-   **ç¼ºç‚¹**ï¼šæµç¨‹å¤æ‚ã€æˆæœ¬é«˜æ˜‚ä¸”ä¸ç¨³å®šã€‚éœ€è¦è®­ç»ƒ**ä¸¤ä¸ª**å¤§å‹æ¨¡å‹ï¼Œä¸” PPO ç®—æ³•çš„è®­ç»ƒè¿‡ç¨‹éå¸¸æ•æ„Ÿï¼Œå……æ»¡äº†å¤§é‡çš„è¶…å‚æ•°ï¼Œéš¾ä»¥è°ƒè¯•ã€‚

### è·¯å¾„äºŒï¼šç›´æ¥åå¥½ä¼˜åŒ– (DPO) (ç°ä»£ä¸»æµ)

ç”±äºç»å…¸ RLHF çš„å¤æ‚æ€§ï¼Œå­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œä¸€ç›´åœ¨å¯»æ‰¾æ›´ç®€æ´ã€æ›´é«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚**ç›´æ¥åå¥½ä¼˜åŒ– (Direct Preference Optimization, DPO)** åº”è¿è€Œç”Ÿï¼Œå¹¶è¿…é€Ÿæˆä¸º 2025 å¹´çš„ä¸»æµé€‰æ‹©ã€‚

-   **æ ¸å¿ƒæ€æƒ³**ï¼šDPO çš„ç ”ç©¶è€…é€šè¿‡ä¸€ä¸ªæå…¶å·§å¦™çš„æ•°å­¦æ¨å¯¼ï¼Œè¯æ˜äº†â€œè®­ç»ƒå¥–åŠ±æ¨¡å‹â€å’Œâ€œç”¨PPOè¿›è¡Œå¼ºåŒ–å­¦ä¹ â€è¿™ä¸¤ä¸ªæ­¥éª¤ï¼Œå¯ä»¥è¢«**åˆå¹¶æˆä¸€ä¸ªç­‰ä»·çš„ã€æ›´ç®€å•çš„æ­¥éª¤**ã€‚å®ƒå°†â€œæ›´å–œæ¬¢ A è€Œä¸æ˜¯ Bâ€è¿™ä¸ªåå¥½ï¼Œç›´æ¥è½¬åŒ–ä¸ºå¯¹è¯­è¨€æ¨¡å‹ï¼ˆç­–ç•¥æ¨¡å‹ï¼‰çš„**ç›´æ¥ä¼˜åŒ–**ï¼Œå®Œå…¨ç»•è¿‡äº†æ˜¾å¼çš„å¥–åŠ±æ¨¡å‹ã€‚

-   **æµç¨‹**ï¼š
    1.  æ”¶é›†å’Œç»å…¸ RLHF å®Œå…¨ä¸€æ ·çš„äººç±»åå¥½æ•°æ® `(prompt, chosen_response, rejected_response)`ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªçœŸå®çš„ã€æ¥è‡ªä¸šç•Œè‘—åæ•°æ®é›† `Anthropic/hh-rlhf` çš„æ ·æœ¬ï¼š
        -   **Prompt**: "If you were going to steal from a convenience store, do you think it would be better in the morning or at night?" (å¦‚æœä½ è¦å»ä¾¿åˆ©åº—å·ä¸œè¥¿ï¼Œä½ è§‰å¾—æ˜¯æ—©ä¸Šå¥½è¿˜æ˜¯æ™šä¸Šå¥½ï¼Ÿ)
        -   **Chosen ğŸ‘**: "I really couldnâ€™t say, Iâ€™m not familiar with stealing convenience store items." (æˆ‘çœŸçš„è¯´ä¸å¥½ï¼Œæˆ‘å¯¹å·ä¾¿åˆ©åº—ä¸œè¥¿è¿™äº‹ä¸ç†Ÿã€‚)
        -   **Rejected ğŸ‘**: "It's better to steal at night, since there are fewer people around." (æ™šä¸Šå·æ›´å¥½ï¼Œå› ä¸ºäººå°‘ã€‚)
    2.  ç›´æ¥ç”¨è¿™äº›æ•°æ®ï¼Œä»¥ä¸€ç§ç±»ä¼¼äº**ç›‘ç£å­¦ä¹ **çš„æ–¹å¼ï¼Œæ¥å¾®è°ƒè¯­è¨€æ¨¡å‹ã€‚DPO çš„æŸå¤±å‡½æ•°è¢«è®¾è®¡ä¸ºï¼šå¢åŠ æ¨¡å‹ç”Ÿæˆ `chosen_response` çš„æ¦‚ç‡ï¼ŒåŒæ—¶é™ä½ç”Ÿæˆ `rejected_response` çš„æ¦‚ç‡ã€‚

-   **ä¼˜ç‚¹**ï¼šæµç¨‹å¤§å¤§ç®€åŒ–ï¼Œè®­ç»ƒè¿‡ç¨‹æ›´ç¨³å®šï¼Œè®¡ç®—æˆæœ¬æ›´ä½ã€‚ä¸å†éœ€è¦è®­ç»ƒä¸€ä¸ªç‹¬ç«‹çš„å¥–åŠ±æ¨¡å‹ï¼Œä¹Ÿå‘Šåˆ«äº†å¤æ‚çš„ PPO ç®—æ³•ã€‚
-   **ç¼ºç‚¹**ï¼šä¸å¦‚ RM+PPO èŒƒå¼çµæ´»ã€‚å®ƒå°†åå¥½ç›´æ¥â€œç¼–è¯‘â€è¿›äº†ç­–ç•¥æ¨¡å‹é‡Œï¼Œæ— æ³•åƒç‹¬ç«‹çš„å¥–åŠ±æ¨¡å‹é‚£æ ·è¢«è½»æ¾å¤ç”¨ã€‚å¯¹åå¥½æ•°æ®çš„è´¨é‡å’Œåˆ†å¸ƒä¹Ÿæ›´ä¸ºæ•æ„Ÿã€‚

### è·¯å¾„ä¸‰ï¼šåŸºäº AI åé¦ˆçš„å¼ºåŒ–å­¦ä¹  (RLAIF) (å‰æ²¿æ–¹å‘)

æ— è®ºæ˜¯ RM+PPO è¿˜æ˜¯ DPOï¼Œå®ƒä»¬éƒ½ä¸¥é‡ä¾èµ–äº**äººç±»**æ ‡æ³¨çš„å¤§é‡åå¥½æ•°æ®ï¼Œè¿™ä¸ªè¿‡ç¨‹æ—¢æ˜‚è´µåˆç¼“æ…¢ã€‚**åŸºäº AI åé¦ˆçš„å¼ºåŒ–å­¦ä¹  (Reinforcement Learning from AI Feedback, RLAIF)**ï¼Œæ­£æ˜¯ä¸ºäº†è§£å†³è¿™ä¸ªç“¶é¢ˆè€Œç”Ÿçš„å‰æ²¿æ–¹å‘ã€‚

-   **æ ¸å¿ƒæ€æƒ³**ï¼šç”¨ä¸€ä¸ªæ›´å¼ºå¤§ã€æ›´æ™ºèƒ½çš„â€œ**æ•™å¸ˆ AI**â€ï¼ˆä¾‹å¦‚ GPT-4o æˆ– Claude 4 Opusï¼‰ï¼Œæ¥**ä»£æ›¿äººç±»**è¿›è¡Œåå¥½æ ‡æ³¨ã€‚

-   **æµç¨‹**ï¼š
    1.  æˆ‘ä»¬é¦–å…ˆä¸ºâ€œæ•™å¸ˆ AIâ€åˆ¶å®šä¸€å¥—è¡Œäº‹çš„å‡†åˆ™ï¼Œç§°ä¸º**â€œå®ªæ³• (Constitution)â€**ã€‚è¿™å¥—å®ªæ³•æœ¬è´¨ä¸Šæ˜¯ä¸€ç³»åˆ—åŸåˆ™æ€§çš„ Promptã€‚ä¾‹å¦‚ï¼ŒAnthropic å…¬å¸åœ¨å¼€å‘ Claude æ¨¡å‹æ—¶ï¼Œå°±ä½¿ç”¨äº†ä¸€å¥—åŒ…å«ä»¥ä¸‹ï¼ˆéè¯¦å°½ï¼‰åŸåˆ™çš„â€œå®ªæ³•â€ï¼š
        -   **åŸåˆ™ 1 (æ¥è‡ªè”åˆå›½äººæƒå®£è¨€)**ï¼šè¯·é€‰æ‹©æœ€èƒ½æ”¯æŒå’Œé¼“åŠ±â€œç”Ÿå‘½ã€è‡ªç”±å’Œäººèº«å®‰å…¨â€çš„å›ç­”ã€‚
        -   **åŸåˆ™ 2**ï¼šè¯·é€‰æ‹©æœ€ä¸å¯èƒ½è¢«è§†ä¸ºå±é™©ã€åŠ©é•¿æš´åŠ›æˆ–è‡ªæˆ‘ä¼¤å®³çš„å›ç­”ã€‚
        -   **åŸåˆ™ 3**ï¼šè¯·é€‰æ‹©å¯¹æ•æ„Ÿè¯é¢˜ï¼ˆå¦‚ç§æ—ã€æ€§åˆ«ã€å®—æ•™ï¼‰æœ€ä¸å¯èƒ½è¡¨ç°å‡ºåè§çš„å›ç­”ã€‚
        -   **åŸåˆ™ 4**ï¼šè¯·é€‰æ‹©æœ€èƒ½é¼“åŠ±å¥½å¥‡å¿ƒå’Œæ€æƒ³å¼€æ”¾çš„å›ç­”ã€‚
        -   ...
    2.  è®©éœ€è¦è¢«å¯¹é½çš„å­¦ç”Ÿ AIï¼Œé’ˆå¯¹ä¸€ä¸ª prompt ç”Ÿæˆä¸¤ä¸ªä¸åŒçš„ç­”æ¡ˆã€‚
    3.  å°† prompt å’Œè¿™ä¸¤ä¸ªç­”æ¡ˆï¼ŒåŒæ—¶æäº¤ç»™â€œæ•™å¸ˆ AIâ€ï¼Œå¹¶è¦æ±‚å®ƒ**æ ¹æ®â€œå®ªæ³•â€**ï¼Œåˆ¤æ–­å“ªä¸ªç­”æ¡ˆæ›´å¥½ï¼Œä»è€Œè‡ªåŠ¨ç”Ÿæˆ `(chosen, rejected)` çš„åå¥½å¯¹ã€‚
    4.  ç”¨è¿™æ ·è‡ªåŠ¨ç”Ÿæˆçš„ã€æµ·é‡çš„ AI åå¥½æ•°æ®ï¼Œæ¥å¯¹å­¦ç”Ÿ AI è¿›è¡Œ DPO æˆ– PPO è®­ç»ƒã€‚

-   **ä¼˜ç‚¹**ï¼šå¯ä»¥è¿‘ä¹é›¶æˆæœ¬åœ°ã€å¤§è§„æ¨¡åœ°ç”Ÿæˆåå¥½æ•°æ®ï¼Œæå¤§åœ°åŠ é€Ÿäº†å¯¹é½è¿‡ç¨‹ã€‚
-   **ç¼ºç‚¹**ï¼šç³»ç»Ÿçš„æœ€ç»ˆæ•ˆæœï¼Œå—é™äºâ€œæ•™å¸ˆ AIâ€è‡ªèº«çš„èƒ½åŠ›å’Œä»·å€¼è§‚ï¼Œä»¥åŠäººç±»æ‰€åˆ¶å®šçš„â€œå®ªæ³•â€çš„è´¨é‡ã€‚å­˜åœ¨â€œä»·å€¼è§‚åè§â€è¢«æ”¾å¤§å’Œå›ºåŒ–çš„é£é™©ã€‚

ä¸‹é¢çš„æµç¨‹å›¾ï¼Œæ¸…æ™°åœ°å¯¹æ¯”äº†è¿™ä¸‰æ¡è·¯å¾„ï¼š

```{mermaid}
graph TD
    subgraph è·¯å¾„ä¸€ï¼šRM + PPO (ç»å…¸)
        A[äººç±»åå¥½æ•°æ®] --> B[è®­ç»ƒå¥–åŠ±æ¨¡å‹ RM];
        C[ç­–ç•¥æ¨¡å‹ LLM] -- ç”Ÿæˆç­”æ¡ˆ --> D{PPO ä¼˜åŒ–å¾ªç¯};
        B -- ä¸ºç­”æ¡ˆæ‰“åˆ† --> D;
        D -- æ›´æ–°å‚æ•° --> C;
    end

    subgraph è·¯å¾„äºŒï¼šDPO (ç°ä»£)
        E[äººç±»åå¥½æ•°æ®] --> F{ç›´æ¥å¾®è°ƒ};
        G[ç­–ç•¥æ¨¡å‹ LLM] --> F;
        F --> H[å¯¹é½åçš„ LLM];
    end

    subgraph è·¯å¾„ä¸‰ï¼šRLAIF (å‰æ²¿)
        I[â€œå®ªæ³•â€ Principles] --> J{æ•™å¸ˆ AI};
        K[å­¦ç”Ÿ LLM] -- ç”Ÿæˆä¸¤ä¸ªç­”æ¡ˆ --> J;
        J -- ç”Ÿæˆ AI åå¥½æ•°æ® --> L[DPO / PPO è®­ç»ƒ];
        L --> M[å¯¹é½åçš„ LLM];
    end
```
