---
title: "7.7 Vibe Coding 实践：Kaggle 竞赛级挑战"
---

欢迎来到本章的 Vibe Coding 实践！

在本节中，你将扮演一位**机器学习系统架构师**的角色。你面前的不再是教科书式的“干净”数据，而是一个源自真实世界研究的、充满挑战的商业问题：**车载场景下的优惠券接受度预测**。

你的任务不是从零开始编写每一行代码，而是通过向你的 AI 编程助手（如 Gemini, Copilot 等）发送**高质量、目标明确的指令 (Prompt)**，引导它完成从数据探索、模型构建、超参数优化到最终模型解释的完整流程。

**我们的目标：**
- **学习如何提出正确的问题**：将模糊的业务目标，转化为清晰、可执行的机器学习任务。
- **掌握指导的艺术**：引导 AI 使用最先进的工具（如 LightGBM, Optuna, SHAP）来解决复杂问题。
- **培养架构师思维**：在精度、速度和可解释性之间做出明智的权衡。

---

### 第〇阶段：理解业务与数据

**商业场景**：一家公司正在开发一个车载智能系统。该系统可以在用户驾车时，根据用户的位置、目的地、以及用户的个人偏好，实时地向其推荐附近的商家优惠券（如咖啡店、餐厅、加油站等）。为了最大化用户体验和商业效益，系统需要一个智能模型来预测：对于当前的这一次推荐，用户会接受（accept）还是拒绝（reject）？

**任务**：给定一系列“用户-环境-优惠券”的推荐记录，预测用户是否会接受这张优惠券。

这是一个典型的**二元分类问题**。

**数据**：本案例的数据源自 UCI 的公开数据集，并在 Kaggle 上广受欢迎：[In-Vehicle Coupon Recommendation](https://www.kaggle.com/datasets/mathurinache/invehicle-coupon-recommendation)。数据在一个 `in-vehicle-coupon-recommendation.csv` 文件中，包含了25个特征和1个目标变量 `Y` (1=接受, 0=拒绝)。

---

### 第一阶段：AI 起草初稿 (AI Writes the First Draft)

你的第一个任务，是让 AI 对数据进行探索性分析 (EDA)，并构建一个简单但可解释的基线模型。这将为我们后续的优化提供一个重要的参考标准。

> **提示 (Prompt):**
>
> “你好，我正在处理一个“车载优惠券推荐”的预测任务。数据在 `in-vehicle-coupon-recommendation.csv` 文件中。
>
> 请帮我完成以下步骤：
>
> 1.  **加载并探索数据**：加载数据，并显示其基本信息（`info()`）和缺失值统计。
> 2.  **数据预处理**：
>     -   为了简化问题，我们先对缺失值进行简单的填充：**数值型特征**的缺失值用**中位数**填充；**类别型特征**的缺失值用字符串**'missing'**填充。
>     -   识别出所有的类别型特征（`object` 类型）。
> 3.  **构建基线模型**：
>     -   将 `Y` 列作为目标变量，其余列作为特征。
>     -   使用 `pd.get_dummies()` 对所有类别型特征进行 **One-Hot 编码**。
>     -   将数据划分为训练集和验证集（8:2划分）。
>     -   使用**逻辑回归**作为基线模型，并对其进行训练。
>     -   在验证集上评估模型的 **AUC (Area Under ROC Curve)** 分数。
>
> 请提供完整的、可执行的 Python 代码。”

*架构师的思考：为什么选择 AUC 作为评估指标？因为这是一个类别不平衡的问题（接受优惠券的比例可能远低于50%），简单的准确率 (Accuracy) 会产生误导。AUC 能更好地衡量模型在所有阈值下的排序能力。*

---

### 第二阶段：人类引导优化 (Human Guides the Optimization)

基线模型可能表现平平。现在，轮到你这位架构师发挥作用了。你需要引导 AI 使用更强大的武器，并进行精细的打磨。

#### **优化方向一：切换到更强大的模型**

> **提示 (Prompt):**
>
> “逻辑回归的 AUC 分数不够理想。我知道这个问题中可能存在很多非线性和特征交互。请帮我换用 **LightGBM** 模型 (`lgb.LGBMClassifier`) 来代替逻辑回归。
>
> -   **重要**：这次请不要使用 One-Hot 编码。LightGBM 原生支持类别特征。请在加载数据后，直接将 `object` 类型的列转换为 `category` 类型，然后直接送入模型。
> -   给出一个基础的 LightGBM 模型在验证集上的 AUC 分数。
> -   为了结果可复现，请设置一个固定的 `random_state`。”

#### **优化方向二：使用 Optuna 进行高效超参数搜索**

> **提示 (Prompt):**
>
> “LightGBM 的表现好多了！现在，让我们用更专业的方式来寻找它的最佳超参数。请使用 **Optuna** 库来为 `lgb.LGBMClassifier` 进行超参数搜索。
>
> -   优化的目标是**最大化验证集的 AUC 分数**。
> -   请为以下核心参数设定一个合理的搜索范围：
>     -   `n_estimators`: (100, 2000)
>     -   `learning_rate`: (0.01, 0.1)
>     -   `num_leaves`: (20, 300)
>     -   `max_depth`: (3, 12)
>     -   `min_child_samples`: (20, 100)
>     -   `subsample` (bagging_fraction): (0.6, 1.0)
>     -   `colsample_bytree` (feature_fraction): (0.6, 1.0)
> -   让 Optuna 运行 **50 次试验 (trials)**。
> -   最后，输出找到的最佳参数组合以及对应的最佳 AUC 分数。”

#### **优化方向三：深度 XAI 洞察**

模型性能达标后，架构师的核心工作才真正开始：**解释模型，并将其转化为商业洞察**。

> **提示 (Prompt):**
>
> “非常好！我们现在有了一个性能强大的 LightGBM 模型。请帮我用 **SHAP** 来深度解释这个使用最佳参数训练出的模型。
>
> 1.  使用 `shap.TreeExplainer` 来计算验证集上的 SHAP 值。
> 2.  绘制一张**全局特征重要性**的 SHAP 总结图 (`summary_plot`)。
> 3.  针对最重要的特征（比如 `coupon`），绘制一张 **SHAP 依赖图 (`dependence_plot`)**，并让它自动显示出与该特征交互最强的另一个特征。
>
> 请提供完整的代码和图表。”

**架构师的灵魂拷问 (基于 SHAP 结果的进一步思考)**
*(这些问题留给你自己，引导你从图表中挖掘价值)*

-   从总结图中，你发现哪些特征是最重要的？是用户的属性（如收入、职业）？还是当时的环境（如天气、目的地）？或是优惠券本身的属性（类型、有效期）？
-   从依赖图中，你看到了什么？
    -   哪种类型的 `coupon` 对用户接受度的贡献最大？
    -   与 `coupon` 交互最强的特征是什么？这揭示了什么样的商业模式？（例如，是不是“餐厅优惠券”只在“乘客是朋友”时才特别有吸引力？或者“咖啡店优惠券”只在“非通勤时段”才有效？）

---

### 第三阶段：架构师的权衡与决策

我们已经有了一个性能强大、且能够被解释的模型。在项目即将上线的最后阶段，你需要从更高维度进行思考。

**思考题 (不需代码，只需回答你的思考):**

1.  **模型选择的权衡**：假如在你的测试中，XGBoost 的 AUC 比 LightGBM 高了 0.005，但其训练时间是 LightGBM 的 3 倍，内存消耗是 4 倍。在这个车载实时推荐的业务场景下，你会选择哪个模型上线？为什么？请陈述你的决策依据。
2.  **特征工程的下一步**：我们这次实践只做了非常初步的特征工程。基于你对业务和模型的理解，请提出**至少三个**你认为最可能提升模型性能的、新的特征工程方向。（例如：用户的历史接受率？该商家优惠券的历史核销率？时间特征与用户职业的交叉特征？）
3.  **模型部署的挑战**：这个模型最终需要被部署在车载系统或云端，为用户的请求提供实时预测。你认为在模型部署时，可能会遇到哪些挑战？（例如：如何实时获取天气、交通等特征？如何保证预测服务的低延迟和高可用性？）

---

通过完成这次 Vibe Coding 实践，你将不再是一个只会调用 API 的“调包侠”，而是一位能够驾驭复杂工具、洞察业务本质、并做出关键决策的、真正的**机器学习系统架构师**。
