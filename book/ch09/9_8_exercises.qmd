---
title: "9.8 练习与思考"
---

### 练习一：概念辨析

请用你自己的话，简要解释以下几组概念之间的核心区别，并说明它们分别解决了什么问题：

1.  **线性层 (Linear Layer) vs. 激活函数 (Activation Function)**
2.  **梯度下降 (Gradient Descent) vs. 反向传播 (Backpropagation)**
3.  **批归一化 (Batch Normalization) vs. Dropout**

### 练习二：网络架构设计

假设你需要为一个三分类任务设计一个全连接网络。输入数据的特征维度是 128。

请你：

1.  画出这个网络的草图（可以用文字描述）。
2.  明确指出输入层、至少一个隐藏层和输出层的神经元数量分别是多少。
3.  为隐藏层和输出层选择合适的激活函数，并解释你为什么这么选。

### 练习三：优化器与学习率的思考

我们在 `9.5` 节中提到，学习率是一个非常关键的超参数。

1.  请描述一下，如果在一个大型、复杂的深度学习任务中，你将**学习率设置得过高**，可能会发生什么现象？（例如，在训练过程中，损失值的变化曲线会是什么样的？）
2.  相反，如果将**学习率设置得过低**，又会带来什么问题？
3.  为什么像 Adam 这样的**自适应优化器**，能够在一定程度上缓解手动调整学习率的困难？

### 练习四：“神级装备”的“反事实”思考

我们在 `9.6` 节学习了三种“神级装备”。现在，请思考它们的“反面”。

1.  **没有残差连接的“超深”网络**：一个没有使用残差连接的、深达 200 层的网络，最可能遇到的训练问题是什么？为什么？
2.  **在“测试阶段”使用 Dropout**：如果在模型的推理（测试）阶段，你忘记关闭 Dropout（即继续随机“失活”神经元），会对模型的预测结果造成什么影响？为什么说这样做通常是不合理的？

### 练习五：Vibe Coding 挑战——回归任务

我们在本章的 Vibe Coding 实践中，解决了一个分类问题。现在，我们来挑战一个回归任务。

**你的任务**：
请创建一个 Vibe Coding Prompt，指导你的 AI 助手，使用 PyTorch 构建一个全连接网络，来拟合一个带噪声的一维非线性函数，例如 `y = sin(x) + noise`。

**你的 Prompt 中需要包含的关键指令应该有**：

1.  **数据生成**：如何生成 x 和带噪声的 y。
2.  **网络架构**：设计一个合适的 FCN 架构（例如，1个输入，2个隐藏层，1个输出）。思考一下，回归任务的**输出层需要激活函数吗**？
3.  **损失函数**：为回归任务选择一个合适的损失函数（例如，`nn.MSELoss`）。
4.  **训练与可视化**：编写训练循环，并在训练结束后，将模型对 x 的预测曲线与原始的 `sin(x)` 真实曲线、以及带噪声的训练数据点，一同绘制在一张图上，以评估拟合效果。
