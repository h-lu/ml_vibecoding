### ch12 审阅报告（已完成）

#### 概览
- 章节：ch12（空间智慧：CNN 与 ViT 的视觉哲学）
- 小节清单与定位：
  - ch12/12_1_business_challenge.qmd
  - ch12/12_2_cnn.qmd
  - ch12/12_3_vit.qmd
  - ch12/12_4_vibe_coding_practice.qmd
  - ch12/12_5_exercises.qmd
- 总体评估：
  - FP：3/4（CNN 三基石与 ViT patching→PE→MHA 的原理叙事完整；可补计算复杂度、正则与训练稳定边界）
  - VC：4/4（动画与实践可视化强，可玩性高）
  - BP：3/4（建议补 PyTorch/torchvision/timm 最新实践、数据与增广、迁移与微调、可解释性与公平合规）
  - 一句话结论：本章心智模型与互动资产良好，补工程化与训练/推理/合规细节可达生产级教学质量。

#### 证据与问题（按小节）
- 12_1 商业挑战（`ch12/12_1_business_challenge.qmd`）
  - 认可点：明确电商图像分类业务目标与从像素→层次特征的 FP 过渡。
  - 建议：补“数据与标签治理”（类不均衡/多标签/弱监督/噪声标签）与评估指标（Top-1/Top-5、mAP）。

- 12_2 CNN（`ch12/12_2_cnn.qmd`）
  - 认可点：参数爆炸与空间结构丢失→局部感受野/参数共享/层次化与池化的推导清晰；含卷积/池化互动 `iframe`。
  - P0（资产路径）：当前 `iframe src="assets/ch12/..."`，而 `assets/ch12/` 目录不存在，动画位于 `assets/ch11/`。建议将 `assets/ch11/convolution_animation.html` 与 `maxpooling_animation.html` 移至 `assets/ch12/` 或修正引用路径为 `../assets/ch11/...`（与章节相对路径一致）以确保构建成功。
  - P1（BP）：
    - 现代实践：减少或移除大池化，使用 stride 卷积；BatchNorm/LayerNorm 使用；残差（ResNet）与 ConvNeXt 等改进；
    - 训练：数据增广（RandAugment/AutoAugment/Mixup/CutMix/RandomErasing）、Label Smoothing；优化器（AdamW）、学习率计划（Cosine + Warmup），AMP 与梯度裁剪；
    - 迁移：冻结骨干、调分类头；小数据集推荐轻量骨干（MobileNet/EfficientNet）。

- 12_3 ViT（`ch12/12_3_vit.qmd`）
  - 认可点：patching→位置编码→编码器与 `[CLS]` 直觉清晰，CNN vs ViT 的权衡表述准确。
  - P1（BP/FP）：
    - 数据需求与正则：ViT 对大数据依赖强，建议配合强增广（RandAugment、Mixup、CutMix、Label Smoothing）、正则（Stochastic Depth/DropPath）、优化器 AdamW；
    - 变体提示：Swin/ConvNeXt/Hybrid CNN+Transformer 的折中；PE 方案（可学习/相对/RoPE 简述）。

- 12_4 实践 Grad-CAM（`ch12/12_4_vibe_coding_practice.qmd`）
  - 认可点：采用 Captum/ResNet50 的 Grad-CAM 实践路线贴合 VC。
  - P0（BP 纠偏）：
    - 推理规范：`model.eval()`、`torch.no_grad()`、构造并传入 `attention_mask` 不适用于 CNN，但需确保输入预处理与标准化（`torchvision.transforms`）一致，固定图像尺寸、均值方差；
    - Captum 用法：对 `LayerGradCam` 需确认目标层（ResNet50 常用 `layer4[-1].conv3` 或等效最后卷积层）；
  - P1：
    - 结果叠加：对 CAM 进行插值到输入分辨率并与原图叠加，控制色图透明度；
    - 多图批处理与保存规范；
    - 给出 `pytorch-grad-cam` 替代实现链接，便于对比。

- 12_5 练习（`ch12/12_5_exercises.qmd`）
  - 认可点：参数共享反事实、架构选型与模型动物园探索好题。
  - 建议：
    - 新增“轻量部署”题：对比 MobileNet/EfficientNet/量化（PTQ/QAT）、蒸馏在移动端的权衡；
    - 新增“公平性”题：提示数据偏见（肤色、性别、年龄）与 Grad-CAM 检查关注点的伦理分析。

#### 修订建议与优先级
- P0
  - 修正 `12_2_cnn.qmd` 中卷积/池化动画 `iframe` 路径与资产缺失问题（创建 `assets/ch12/` 或改为引用 `../assets/ch11/`）。
  - 在 `12_4` 实践中补推理规范（`eval/no_grad`）、正确的目标层选取说明与标准预处理配置。

- P1
  - 补充现代训练配置：数据增广套件、AdamW+Cosine、AMP、梯度裁剪、Label Smoothing、Stochastic Depth；
  - 迁移学习与小数据策略：冻结/解冻策略与分层学习率；
  - ViT 正则与变体：Swin/ConvNeXt/Hybrid 提示与参考链接；
  - 评估指标与数据治理：Top-1/Top-5、mAP，类不均衡（加权损失/重采样）、多标签任务设置。

- P2
  - 统一术语：感受野/参数共享/特征图/池化/步幅/BN/LN/残差/DropPath；patch/PE/CLS/MHA；
  - 可视化：导出 Grad-CAM 叠加图示例，加入图像可访问性对比度提示（WCAG 2.2）。

#### 资源与可复现性
- 资产：`assets/ch12/` 目录缺失；当前动画位于 `assets/ch11/`。建议迁移或修正路径，确保构建。
- 代码与环境：
  - 依赖：`torch`（≥2.3）、`torchvision`、`timm`（ViT/ConvNeXt 等预训练）、`captum`、`matplotlib`、`opencv-python`（可选叠图）；
  - 训练配置：固定随机种子；启用 AMP；显式记录输入分辨率、均值/方差、增广策略；
  - 输出：将 Grad-CAM 结果以 PNG/HTML 保存，并在文中以 `<img>`/`<iframe>` 引用。

#### 术语与引用（访问日期 2025-08）
- CNN 基础与 ResNet：
  - https://pytorch.org/vision/stable/models.html
  - He et al., Deep Residual Learning for Image Recognition, 2015
- ViT 与现代视觉骨干：
  - Dosovitskiy et al., An Image is Worth 16x16 Words (ViT), 2020
  - https://github.com/huggingface/pytorch-image-models (timm)
- 训练与优化：
  - PyTorch AMP/优化器与调度器：https://pytorch.org/docs/stable/optim.html
  - torchvision transforms：https://pytorch.org/vision/stable/transforms.html
- 可解释性：
  - Captum Grad-CAM：https://captum.ai/api/layer_grad_cam
  - Selvaraju et al., Grad-CAM, 2016：https://arxiv.org/abs/1610.02391
  - pytorch-grad-cam：https://github.com/jacobgil/pytorch-grad-cam
- 可访问性（配色对比）：
  - WCAG 2.2：https://www.w3.org/TR/WCAG22/

#### 状态与动作
- 审核状态：已完成（5/5）
- 后续动作：
  - P0：修正动画 `iframe` 路径或迁移资产目录；修补 12.4 推理与目标层说明；
  - P1：补现代训练/增广/迁移/正则/评估与治理；
  - P2：统一术语与可视化资产导出。

