---
title: "15.4 文档分块的艺术：如何把“大象”切成“小块”"
---

在 RAG 系统中，**分块（Chunking）** 是一个看似简单，却极度考验架构师“手艺”的关键环节。它的好坏，直接决定了检索的精度和最终生成答案的质量。

### 为什么需要分块？

我们不能把一篇长达一万字的 PDF 文档或者一篇复杂的网页，整个转换成一个单独的向量。原因有二：

1.  **信息密度过低**：一个巨大的文档包含了太多不同的主题和细节。如果将其压缩成一个唯一的向量，这个向量的语义会变得非常模糊和泛化，就像试图用一句话总结一整本百科全书一样，会丢失掉所有有价值的信息。在进行相似性搜索时，这样的“平均向量”很难与一个具体、精确的问题向量产生高匹配度。
2.  **超出上下文窗口**：即使我们检索到了这个巨大的文档块，LLM 的上下文窗口（Context Window）也无法容纳它。大多数模型都有几千到几十万 Token 的输入限制，过长的上下文会被直接截断。

因此，我们必须把原始文档这头“大象”，巧妙地切成大小适中、意义完整的“小块肉”，也就是**文档块（Chunks）**。

### 常见分块策略

不同的文档类型和业务需求，需要不同的分块策略。

#### 1. 固定大小分块 (Fixed-size Chunking)

这是最简单、最粗暴的方法。我们设定一个固定的 `chunk_size`（例如，500个字符）和一个 `chunk_overlap`（例如，50个字符），然后像切香肠一样，从头到尾切割文档。

-   **优点**：实现简单，计算开销小。
-   **缺点**：非常容易“拦腰斩断”一个完整的句子、段落甚至代码块，严重破坏文本的语义完整性。
-   **适用场景**：只适用于那些本身没有明显结构、可以任意切分的纯文本数据。

#### 2. 递归字符分块 (Recursive Character Text Splitting)

这是目前最常用、也更智能的一种策略。它会尝试按照一个预设的分隔符列表，进行**有优先级的、递归的**切分。

例如，一个典型的分隔符列表是 `["\n\n", "\n", " ", ""]`。切分器会：

1.  首先尝试用**两个换行符 `\n\n`**（代表段落）来切分整个文档。
2.  对于切分后，仍然**超过** `chunk_size` 的段落，它会**退一步 (fall back)**，尝试用**单个换行符 `\n`**（代表句子）来切分这个段落。
3.  如果还有更长的句子，它会继续退一步，尝试用**空格 ` `** 来切分。
4.  最后，如果连单词都超过了长度，它才会粗暴地按字符切分。

-   **优点**：通过这种递归和“优雅降级”的策略，它能最大程度地保持文本的语义连贯性，优先保留段落和句子的完整。
-   **适用场景**：绝大多数纯文本文档，如`.txt`, `.md`等。

#### 3. 文档结构感知分块 (Layout-aware Chunking)

这是最先进、也最复杂的一种策略。它不仅仅将文档视为纯文本，而是会**解析文档的内在结构**。

-   **对于 HTML/XML 文档**：它可以根据 `<h1>`, `<h2>`, `<p>`, `<li>` 等标签来进行切分，确保每个标题和它所属的段落内容被分在一起。
-   **对于 Markdown 文档**：它可以根据 `#` 标题、列表项 `-`、代码块 ` ``` ` 等语法来进行切分。
-   **对于 PDF 文档**：一些高级的解析库（如 `unstructured.io`）能够识别出 PDF 中的标题、页眉页脚、表格和图片，并进行结构化的切分。

-   **优点**：切分出的文档块质量最高，语义最完整、最聚焦。
-   **缺点**：实现复杂，计算开销大，高度依赖于源文档的结构化程度。

### 架构师的核心挑战：没有银弹

作为系统架构师，你必须认识到，**分块策略没有“银弹”**。最优的 `chunk_size` 和 `chunk_overlap` 是多少？这是一个需要根据你的具体业务场景，通过反复实验和评估来找到的**超参数 (Hyperparameter)**。

-   **分块太小**：会导致上下文信息不足。检索到的文档块虽然相关，但LLM无法仅凭这“一孔之见”来回答需要更广阔背景知识的问题。
-   **分块太大**：会导致噪声过多。检索到的文档块虽然包含了答案，但也夹杂了大量不相关的信息，这会干扰 LLM 的注意力，降低答案的精确性。

寻找最佳分块策略的过程，本身就是 RAG 系统优化的核心工作之一，它直接体现了架构师对业务数据和 AI 模型双重深刻理解的价值。


