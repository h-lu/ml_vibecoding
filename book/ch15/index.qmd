---
title: "第15章 AI 的“世界模型”：构建可信的检索增强生成(RAG)系统"
---

> "未来的AI，其价值不在于知道多少，而在于能多快、多准地找到并运用它所不知道的知识。RAG，就是连接‘无所不知’的语言模型与‘真实世界’的知识库之间的那座桥梁。"

::: {.callout-note}
## 从“初识”到“精通”

在 [第十章：语言智能的核心引擎](ch10/index.qmd) 中，我们已经初步接触了 RAG 架构，并搭建了一个可以工作的原型。那一章的重点是让你**首次理解** RAG 如何解决 LLM 的知识局限问题。

本章，我们将进行一次“深潜”。我们的视角将从“功能实现者”全面转向“系统架构师”。我们将深入探讨在构建一个**生产级 (Production-Level)** RAG 系统时，所必须面对的各种权衡、优化与挑战，例如：
- 如何选择最合适的向量数据库和嵌入模型？
- “文档分块”这门手艺有哪些独到的技巧？
- 如何通过元数据过滤和混合搜索，实现更精准的检索？
- 如何保障 RAG 系统的安全性，抵御数据投毒等攻击？

准备好，让我们从一个“能跑通”的 RAG，迈向一个“信得过、用得好”的 RAG。
:::

在本章中，我们将深入探讨当今大语言模型应用领域最核心、最热门的架构之一：检索增强生成 (Retrieval-Augmented Generation, RAG)。我们将从第一性原理出发，理解为什么 LLM 需要 RAG，并动手实践，构建一个完整的、可信的 RAG 系统。

## 学习目标

- **具体技能**：
  - 能够实现一个完整的**检索增强生成 (RAG)** 流程：**加载数据 -> 切分文档 (Chunking) -> 嵌入化 (Embedding) -> 存入向量数据库 -> 检索 (Retrieve) -> 生成 (Generate)**。
  - 掌握不同的**文档切分策略**（如固定大小、递归字符切分）及其对检索效果的影响。
  - 能够利用**混合搜索 (Hybrid Search)**，结合向量的语义相似性和关键词过滤，实现更精确的检索。
  - 学会使用 `ChromaDB` 或 `Qdrant` 等现代向量数据库，并了解其核心配置。
- **理论理解**：
  - 理解 **RAG 的第一性原理**：通过在生成答案前，先从外部知识库中检索相关信息并注入到提示词中，来解决 LLM 的知识陈旧、幻觉和无法访问私有数据三大核心问题。
  - 理解**嵌入模型 (Embedding Models)** 的选择标准，并了解不同模型（如 `CLIP` 用于图文，`BGE-M3` 用于多语言文本）的适用场景。
  - 理解 **RAG 的安全挑战**，特别是 OWASP LLM Top 10 中提到的**数据投毒 (Data Poisoning)** 和**嵌入反演攻击 (Embedding Inversion)**。
- **实践应用**：
  - 能够为一个企业设计并构建一个基于内部文档的“智能知识库问答”机器人。
  - 能够为一个法律或医疗等专业领域，设计一个既能理解专业术语、又能保证信息来源可靠的 AI 助。
