---
title: "第十三章：迁移学习与 Transformer 架构模式"
---

## 本章学习目标

欢迎来到深度学习实践中最为强大和高效的领域之一！在本章中，我们将深入探讨“站在巨人的肩膀上”的智慧——**迁移学习 (Transfer Learning)**，以及在当今自然语言处理领域占据主导地位的、基于 Transformer 的各种**架构模式**。

通过本章的学习，你将能够：

1.  **理解迁移学习的核心思想**：
    -   解释为什么从零开始训练一个大型模型通常是低效且不必要的。
    -   掌握“预训练 (Pre-training)”和“微调 (Fine-tuning)”这两个核心概念。
    -   理解“特征提取 (Feature Extraction)”作为一种微调策略的适用场景。

2.  **掌握关键的微调技术**：
    -   学习如何“冻结”模型的不同部分，以保留通用知识并训练特定任务。
    -   了解什么是“分类头 (Classifier Head)”，以及如何为特定任务定制它。
    -   接触到“参数高效微调 (Parameter-Efficient Fine-Tuning, PEFT)”的前沿思想，特别是 LoRA (Low-Rank Adaptation) 的基本原理。

3.  **辨析主流的 Transformer 架构**：
    -   **编码器-解码器 (Encoder-Decoder) 架构**：了解其工作原理（如 T5, BART），以及它在序列到序列任务（如翻译、摘要）中的应用。
    -   **仅编码器 (Encoder-Only) 架构**：了解其工作原理（如 BERT），以及它在自然语言理解任务（如分类、命名实体识别）中的强大能力，特别是其对“双向上下文”的理解。
    -   **仅解码器 (Decoder-Only) 架构**：了解其工作原理（如 GPT 系列），以及它在自回归生成任务（如文本生成、对话系统）中的核心地位，特别是其对“单向上下文”的依赖。

4.  **建立架构师的决策框架**：
    -   能够根据具体的业务问题和数据特点，在不同的 Transformer 架构之间做出明智的技术选型。
    -   理解每种架构的优势、劣势以及它们最适合的应用场景。

本章将为你揭示现代 AI 应用如何能够以前所未有的速度和效率被开发出来，而其中的关键，正是巧妙地利用已有的知识，并为特定的“战场”选择最合适的“武器”。
