---
title: "6.6 练习与作业"
---

本章的练习将帮助你巩固对分类模型、非线性决策以及处理不平衡数据重要性的理解。

### 1. 伦理讨论：AI 招聘中的偏见

**场景**：

一家公司使用AI模型来筛选工程师简历。模型在训练后，发现“毕业院校”是一个非常重要的特征，它给予了名校毕业生显著更高的分数。模型的准确率在历史数据上表现优异。

**问题**:

1.  你认为这个模型是否存在偏见？为什么？
2.  这种基于“毕业院校”的强关联性，是反映了候选人的“真实能力”，还是数据中潜藏的“社会偏见”？请阐述你的观点。
3.  作为这个AI系统的架构师，如果你发现了这个问题，你会建议采取哪些措施来干预或修正模型？

### 2. 模型选择：可解释性 vs. 性能

**场景**：

你正在为一家银行构建一个贷款审批模型。你有两个备选方案：

-   **方案A**：一个逻辑回归模型。
-   **方案B**：一个使用了RBF核的支持向量机（SVM）模型。在测试集上，方案B的各项性能指标（如F1-score, AUC）都略高于方案A。

**问题**:

1.  如果银行的监管部门要求你提供一套**稳定、透明、对所有客户都适用的全局审批规则**，并能清晰地解释**模型内在的判断逻辑**（例如，“因为您的年收入每增加一万元，您的信用评分就会提升5分”），你会选择哪个方案？为什么？
2.  如果你的首要目标是**不惜一切代价最大化模型对个案的预测准确性**，并且你只需要对**每一个独立的审批结果**进行事后归因分析（Post-hoc Explanation），你会选择哪个方案？
3.  这个选择题揭示了在构建机器学习系统时，哪两个核心目标之间常常存在需要权衡（Trade-off）的关系？（提示：一个关于模型自身的透明度，另一个关于模型的预测能力）

### 3. Vibe Coding 挑战：SVM 参数的可视化探索

**任务**:

这是一个非常经典的Vibe Coding挑战，可以让你直观地感受到SVM超参数的威力。请你指导AI完成以下任务：

1.  **生成数据**：
    -   使用 `sklearn.datasets.make_moons` 函数生成一个包含200个样本、带有少量噪声（`noise=0.2`）的“月亮形”非线性数据集。
    -   使用 `sklearn.datasets.make_circles` 函数生成一个类似的“环形”数据集。

2.  **训练与可视化**：
    -   对于每个数据集，分别训练一个使用了RBF核的SVM分类器 (`sklearn.svm.SVC`)。
    -   请AI编写一个函数，该函数可以接收一个训练好的SVM模型和数据集，然后**可视化这个模型的决策边界**。 (提示: 可以搜索 "scikit-learn plot decision boundary" 来寻找常用的可视化方法，例如使用 `matplotlib.pyplot.contourf`)。

3.  **探索超参数**:
    -   **探索 `gamma`**：保持 `C=1` 不变，尝试不同的 `gamma` 值（例如 `0.1`, `1`, `10`, `100`）。观察并描述当 `gamma` 值从低到高变化时，决策边界是如何从“平滑”变得越来越“扭曲”和“过拟合”的。`gamma` 值控制了单个样本的影响范围，值越小，影响范围越大。
    -   **探索 `C`**：保持 `gamma=1` 不变，尝试不同的 `C` 值（例如 `0.1`, `1`, `10`, `100`）。`C` 是正则化参数，它控制了对误分类样本的“惩罚”程度。观察并描述当 `C` 值从低到高变化时，决策边界是如何从“容忍更多错误”变得越来越“试图完美分割所有点”的。

这个练习将极大地加深你对SVM如何通过调整超参数来适应不同数据分布的理解。
