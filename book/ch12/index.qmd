---
title: "第十二章：空间智慧：CNN 与 ViT 的视觉哲学"
---

> *“我们看的方式，决定了我们所看到的东西。” —— 约翰·伯格*

欢迎来到第十二章。在过去的篇章中，我们深入探索了如何处理“序列”数据，并理解了驱动现代语言智能的 Transformer 架构。现在，我们将把目光转向另一个同样广阔而迷人的领域：**计算机视觉 (Computer Vision)**。

对人类来说，“看”是一种与生俱来的、毫不费力的本能。但对机器而言，一张图片只是一个由海量像素点构成的、毫无意义的巨大数字矩阵。如何让机器从这片像素的海洋中，分辨出边缘、识别出纹理、组合出形状，并最终像我们一样喊出“这是一只猫！”——这便是计算机视觉的核心挑战，也是“空间智慧”的本质。

在本章，我们将探索两种解决这个问题的、截然不同但都极其成功的哲学思想：

1.  **卷积神经网络 (Convolutional Neural Network, CNN)**：这是一种源于生物启发的智慧。CNN 模仿了生物视觉皮层的工作方式，通过**局部感受野**、**参数共享**和**层次化特征提取**这三大基石，高效地从像素中构建出对世界的认知。我们将从第一性原理出发，理解为什么 CNN 的设计如此巧妙，以及它为何在过去十年间统治了计算机视觉领域。

2.  **视觉 Transformer (Vision Transformer, ViT)**：这是一种全新的、颠覆性的“看法”。当所有人都认为 Transformer 是为语言而生时，研究者们大胆地提问：我们能否像处理句子一样处理图片？通过将图片切分成一个个“小块”（Patches），ViT 将 Transformer 强大的全局注意力机制成功地引入了视觉领域，并取得了惊人的效果，对 CNN 的主导地位发起了强有力的挑战。

在本章的 Vibe Coding 实践中，我们将亲手利用一个在海量数据上预训练好的 CNN 模型，来解决一个真实的图像分类问题。你将学会如何“窥探”模型的内部，观察它在“看”一张图片时，究竟是被哪些区域所激活，从而建立起对模型行为的直观理解。

准备好进入这个充满色彩、形状和纹理的世界了吗？让我们一起开始探索机器的“视觉”之旅。
