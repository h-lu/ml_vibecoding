---
title: "12.5 练习与思考"
---

### 练习一：参数共享的“反事实”思考

我们在 12.2 节中学习到，参数共享是 CNN 的核心基石之一，它假设一个特征检测器在图像的任何位置都应该有效。

现在，请进行一个“反事实思考”：**请你设想一个特殊的图像分类任务，在这个任务中，“参数共享”这个假设可能是不成立的，甚至是“有害”的。**

请描述这个任务是什么，并解释为什么在这个任务中，“一个特征的重要性”会高度依赖于它在图像中的“位置”。

（提示：可以从一些需要精确对齐和识别人脸特征的任务，或者一些需要分析固定构图的医学影像任务来思考。）

### 练习二：数据规模与架构选型

假设你是一位初创公司的机器学习架构师，你面临两个不同的项目：

-   **项目 A**：你需要为一个移动应用开发一个“花卉识别”功能。你目前只有一支小团队，通过拍照和众包，辛苦收集了大约 5,000 张标注好的、包含约 100 种常见花卉的图片。你的首要目标是在三个月内，快速上线一个效果“还不错”的原型。

-   **项目 B**：你与一家大型自动驾驶研究机构合作，他们为你提供了过去五年积累的海量、高质量的道路场景数据集，包含了数千万帧的、经过精细标注的图像。你的目标是为他们的下一代感知系统，研发一个性能要超越当前所有已知模型的图像识别模块，性能是第一追求，研发周期和计算资源相对充裕。

对于这两个项目，你会分别倾向于选择哪种基础架构（CNN-based vs. ViT-based）？请详细阐述你的理由，并说明你在做决策时，主要权衡了哪些因素（例如：归纳偏置、数据效率、性能上限、开发成本、生态系统成熟度等）。

### 练习三：Vibe Coding 挑战——深入探索模型动物园

Hugging Face Hub 和 `torchvision.models` 就像是一个庞大的“模型动物园”，里面有许多在 ImageNet 上预训练好的、名字各异的 CNN 模型（例如 ResNet, VGG, Inception, MobileNet 等）。

这些模型虽然都遵循 CNN 的基本思想，但它们在具体的“宏观架构”设计上（例如，如何组织卷积层、如何设计残差连接、如何平衡深度和宽度等）却各有千秋，以应对不同的性能和效率目标。

**你的任务**：
请选择任意**两个**你感兴趣的、不同的预训练 CNN 模型（例如，`ResNet50` 和 `MobileNetV2`）。

**指导你的 AI 助手，为你完成以下探索：**

1.  **加载并打印模型结构**：让 AI 为你加载这两个模型，并打印出它们完整的网络结构。
2.  **分析与对比**：仔细观察这两个模型的结构打印结果，并结合搜索到的资料，回答以下问题：
    -   这两个模型在“深度”（层数）和“宽度”（通道数/滤波器数量）上有什么显著差异？
    -   `ResNet50` 最著名的设计是“残差连接 (Residual Connection)”，它在网络结构中是如何体现的？
    -   `MobileNetV2` 的核心是“深度可分离卷积 (Depthwise Separable Convolution)”，这个设计主要是为了解决什么问题？（提示：与计算效率和移动端部署有关）
3.  **总结**：简要总结这两个模型在设计哲学上的核心差异，以及它们分别最适合的应用场景。
