# 第6章：分类问题：逻辑回归与支持向量机

> *从概率和几何视角拆解线性分类器*

## 学习目标

- **掌握分类问题的本质**：从第一性原理理解分类是在特征空间中寻找“决策边界”来区分不同类别。
- **精通逻辑回归与SVM**：不仅会用，更能从几何（最大间隔）、概率（几率）的角度解释逻辑回归和支持向量机的工作原理。
- **理解不同模型的权衡**：认识到逻辑回归和SVM在可解释性、线性和非线性能力上的不同定位。
- **即时应用 XAI**：学会在构建分类模型后，立即使用 XAI 工具来解释决策依据，并识别潜在的数据偏见。
- **实践 Vibe Coding 的分类工作流**：高效处理不平衡数据，并权衡不同类别错分的业务成本。

## 章节结构

### 6.1 商业挑战：做出“是”或“否”的判断

- **开篇商业挑战**：一家电信公司希望识别哪些客户有可能会在下个月流失，以便提前进行挽留。这是一个典型的二元分类问题。
- **第一性原理**：分类的本质是在代表客户的特征空间中，画出一条“线”或一个“面”（即**决策边界, Decision Boundary**），将“可能流失”的客户和“不太可能流失”的客户分隔开。

### 6.2 两种基础思路：概率 vs. 几何

- **逻辑回归 (Logistic Regression)：概率视角**
    - **核心思想**：它不直接预测类别，而是预测属于某个类别的**概率**。它通过 Sigmoid 函数，将线性的输出值“压扁”到 0 和 1 之间，形成一个优美的 S 形曲线。
    - **直觉**：逻辑回归是在拟合“几率”（Odds），即事件发生的概率与不发生的概率之比。
    - **互动动画**：展示随着一个特征（e.g., 上月通话时长）的变化，客户流失的预测概率是如何沿着 S 形曲线变化的。
- **支持向量机 (Support Vector Machine, SVM)：几何视角**
    - **核心思想**：SVM 的目标是找到一个决策边界，使其距离两边最近的数据点（即**支持向量, Support Vectors**）的**间隔 (Margin)** 最大化。它追求的是最“稳健”、最“安全”的划分。
    - **物理类比**：想象在两类数据点之间，放入一个尽可能“胖”的“通道”，这个通道的中心线就是最佳决策边界。
    - **互动动画**：展示在二维空间中，不同的决策边界如何产生不同的间隔，并高亮显示出决定了最终边界的支持向量。

### 6.3 核技巧：SVM的非线性魔法

- **问题引入**：如果数据是线性不可分的（例如，一个环形的数据集），直线决策边界会失效。我们该怎么办？
- **核心思想（核技巧, Kernel Trick）**：通过一个非线性映射函数，将数据从原始的低维空间投射到一个更高维的新空间。在这个新空间里，原本线性不可分的数据可能就变得线性可分了。
- **直觉类比**：就像一张平铺的纸上的红点和蓝点混在一起，我们把纸“向上”一折，红点和蓝点就在不同的高度上分开了，可以用一个平面轻易切分。
- **常见的核函数**：
    - **多项式核 (Polynomial Kernel)**
    - **径向基函数核 (Radial Basis Function, RBF)**
- **互动动画**：展示使用RBF核的SVM如何轻松地为一个环形数据集找到完美的非线性决策边界。

### 6.4 即时引入 XAI：警惕模型中的偏见

- **为什么 XAI 在分类中至关重要**：一个错误的分类决策（e.g., 在招聘中错误地拒绝一位合格的少数族裔候选人）可能会带来严重的伦理和法律后果。
- **使用 SHAP 进行分析**：
    - **实践**：对客户流失模型进行 SHAP 分析，找出导致模型将客户预测为“流失”的最主要因素。
    - **识别偏见**：检查是否有某个受保护的特征（e.g., 用户的注册区域、年龄段）对预测结果产生了不应有的巨大影响，这可能是数据偏见的信号。

### 6.5 Vibe Coding 实践：处理不平衡的世界

- **任务描述**：在客户流失数据集中，通常流失的客户是少数（e.g., 占 5%），这被称为**类别不平衡 (Class Imbalance)**。
- **第一阶段：AI 暴露问题 (10分钟)**
    - **提示 (Prompt)**：“使用逻辑回归，为这个客户流失数据集构建一个分类模型，并报告其准确率 (Accuracy)。”
    - **学生观察**：AI 可能会报告一个看似很高的准确率（e.g., 95%）。但学生会发现，这是一个陷阱——如果模型简单地将所有人都预测为“不流失”，它也能达到 95% 的准确率。
- **第二阶段：人类引导优化 (30分钟)**
    - **引导性问题**：
        1.  **评估指标**：对于不平衡问题，准确率是一个好的指标吗？我们是否应该关注**精确率 (Precision)**、**召回率 (Recall)** 或 **F1-score**？
        2.  **数据层面**：我们能否通过**过采样 (Oversampling)** 少数类（e.g., SMOTE）或**欠采样 (Undersampling)** 多数类来平衡数据？
        3.  **模型层面**：我们能否在模型中设置 `class_weight='balanced'` 来告诉模型要更加关注少数类？
    - **学生动手**：
        - 指导 AI 使用更合适的评估指标。
        - 指导 AI 应用 SMOTE 来处理数据不平衡。
        - 比较不同处理方式对模型性能的影响，并根据业务目标（我们更害怕“错放”还是“错杀”？）选择最佳策略。

## 练习与作业

1.  **伦理讨论**：在一个用 AI 进行招聘筛选的场景中，假设模型在“能力”和“毕业院校”两个特征上学到了很强的关联。请讨论这是否构成偏见？为什么？我们应该如何干预？
2.  **模型选择**：如果你的首要任务是需要向老板解释模型为什么会做出某个具体的分类决策，你会选择逻辑回归还是SVM（使用RBF核）？为什么？
3.  **Vibe Coding 挑战**：指导 AI 生成一个二维数据集，并训练一个带有 RBF 核的 SVM 分类器。请 AI 可视化这个决策边界，并尝试通过调整 SVM 的 `C` 和 `gamma` 参数，观察决策边界是如何从平滑变得“过拟合”的。
