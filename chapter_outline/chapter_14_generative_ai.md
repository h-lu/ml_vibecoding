# 第14章：生成式 AI：从 GAN 到 GPT 的创造之旅

> *从像素的随机博弈，到语言的优雅续写*

## 学习目标

- **掌握三大生成模型范式**：从第一性原理理解生成对抗网络（GAN）的“博弈”思想、扩散模型的“有序去噪”思想，以及自回归模型的“序列预测”思想。
- **精通 Decoder-Only 架构**：深入理解 Decoder-Only 架构与自回归生成 (Autoregressive Generation) 的工作原理，并掌握其核心组件——带掩码的自注意力（Masked Self-Attention）。
- **理解文本生成的解码策略**：了解贪心搜索（Greedy Search）、束搜索（Beam Search）和带温度的随机采样（Temperature Sampling）等不同解码策略的优缺点。
- **实践 Vibe Coding 的生成任务**：学会指导 AI 完成一个条件生成任务，并由人类专注于设计和优化指导模型行为的提示（Prompt）。

## 章节结构

### 14.1 商业挑战：从“预测分析”到“内容创造”

- **开篇商业挑战**：
    - **场景1 (图像)**：一家家具公司希望根据用户的文字描述（e.g., “一张斯堪的纳维亚风格的木质椅子”），自动生成逼真的产品设计图。
    - **场景2 (文本)**：一家市场营销公司，需要为上千种不同的商品，快速生成吸引人的、风格一致的营销文案。
- **超越监督学习**：这些挑战不再是简单的预测，而是要求模型具备**从无到有、创造新内容**的能力。

### 14.2 生成对抗网络 (GAN)：一场“伪造者”与“鉴赏家”的博弈

- **第一性原理**：GAN 的灵感来自博弈论。它由两个相互竞争的神经网络组成：
    - **生成器 (Generator)**：一个“艺术伪造者”，试图凭空（从随机噪声）创造出以假乱真的数据。
    - **判别器 (Discriminator)**：一个“艺术鉴赏家”，试图分辨出哪些是真实数据，哪些是生成器伪造的赝品。
- **训练过程**：两者在“军备竞赛”中共同进化，最终生成器能创造出让判别器无法分辨的、高质量的数据。
- **互动动画**：可视化一个在一维数据上训练 GAN 的过程，展示生成器产生的点如何从随机分布，逐渐学习到与真实数据分布相匹配。

### 14.3 扩散模型 (Diffusion Models)：从混沌中有序地创造

- **第一性原理**：扩散模型的灵感来自热力学。它包含两个过程：
    - **前向过程（加噪）**：逐步地、有控制地向真实图片添加高斯噪声，直到其变成纯噪声。
    - **反向过程（去噪）**：训练一个神经网络学习这个过程的“逆操作”，从纯噪声开始，一步步地“雕刻”出一张清晰的图片。
- **核心优势**：相比 GAN，训练更稳定，生成质量和多样性通常更高，且更容易通过文本等条件来引导生成（e.g., Stable Diffusion, Midjourney）。

### 14.4 自回归模型：优雅的文本续写者

- **承前启后**：在第12章，我们已经知道 Decoder-Only 架构是为生成任务而生的。现在，我们深入其内部。
- **核心机制：自回归 (Autoregressive)**
    - 模型像一个作家一样，一次只生成一个词（Token）。
    - 每生成一个新词，这个词就会被添加回输入序列，成为下一步生成下一个词的上下文（条件）。
- **关键组件：带掩码的自注意力 (Masked Self-Attention)**
    - 为了强制实现这种“只能看左边”的自回归特性，Decoder 内部的自注意力机制被施加了一个**掩码 (Mask)**。
    - 在计算注意力分数时，这个掩码会强制将当前位置之后所有位置的注意力权重设为一个极大的负数（接近负无穷），这样在经过 Softmax 后，它们的权重就几乎为零。
    - 这确保了在预测第 `t` 个词时，模型**绝对无法**“偷看”到第 `t+1` 个词及之后的信息。
- **解码策略 (Decoding Strategy)**：当模型为下一个词预测出成千上万个可能的概率分布后，我们如何选择最终的词？
    - **贪心搜索 (Greedy Search)**：总是选择概率最高的那个词。最简单，但容易产生重复、无趣的文本。
    - **束搜索 (Beam Search)**：在每一步保留 `k` 个最可能的序列，并在下一步从这 `k` 个序列出发继续探索。在准确性和流畅性之间取得了更好的平衡。
    - **随机采样 (Sampling)**：根据概率分布进行随机抽样，可以通过一个**温度 (Temperature)** 参数来控制其“创造性”。温度越高，随机性越强，越可能产生惊喜（或胡言乱语）；温度越低，则越接近贪心搜索。

### 14.5 Vibe Coding 实践：设计一个“创意广告”生成器

- **任务描述**：利用一个预训练好的 Decoder-Only 模型（如 GPT-2 或一个更小的开源模型），构建一个能根据“产品名称”和“核心卖点”生成广告文案的应用。
- **第一阶段：AI 快速实现生成功能 (10分钟)**
    - **提示 (Prompt)**：“使用 Hugging Face Transformers 库，加载一个预训练的 GPT-2 模型和分词器。请编写一个函数，该函数接收一个文本开头（prompt），并使用 `model.generate()` 方法来续写它。请在 `generate` 方法中使用带温度的随机采样解码策略。”
- **第二阶段：人类通过 Prompt Engineering 引导创造 (30分钟)**
    - **任务**：AI 搭建了基础的生成功能，但它生成的文案可能平淡无奇。人类架构师的核心价值在于，通过设计精巧的 Prompt，来“激发”模型的创造力，并约束其输出的格式和风格。
    - **引导性问题**：
        1.  **基础 Prompt**：如果我们直接输入 `产品：空气炸锅，卖点：无油、健康`，模型可能会生成什么？
        2.  **风格引导**：我们能否在 Prompt 中加入风格指令？（e.g., `请用一种幽默、夸张的风格...`）
        3.  **结构化输出（Few-shot Prompting）**：我们能否在 Prompt 中提供一两个完整的“输入-输出”范例，来“教会”模型我们想要的输出格式？这种技术被称为“少样本提示 (Few-shot Prompting)”。
    - **学生动手**：
        - 设计并实验至少三个不同版本的 Prompt（基础版、风格引导版、Few-shot 版）。
        - 比较不同 Prompt 生成结果的质量，并分析为什么好的 Prompt 能极大地提升生成效果。
        - 撰写报告，总结你学到的 Prompt Engineering 的核心技巧。

## 练习与作业

1.  **解码策略权衡**：在为一个需要生成高度精确、事实性内容的任务（如根据财报数据生成新闻稿）选择解码策略时，你会倾向于使用贪心搜索/束搜索，还是带温度的随机采样？为什么？
2.  **GAN vs. 自回归**：如果你想生成一段连贯的音乐（一个序列），你认为 GAN 和自回归模型哪个在概念上更适合这个任务？请阐述你的理由。
3.  **Vibe Coding 挑战**：扩散模型不仅能生成图片，理论上也能生成其他类型的数据。请你畅想一下，如何设计一个基于扩散模型的“文本生成”过程？（提示：思考文本的“加噪”和“去噪”过程可能是什么样的）。请指导 AI，为你搜索并解释相关的研究方向（如 Denoising Diffusion Probabilistic Models for Text）。
