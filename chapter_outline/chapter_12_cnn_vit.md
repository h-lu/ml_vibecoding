# 第12章：空间智慧：CNN 与 ViT 的视觉哲学

> *生物启发的空间智能*

## 学习目标

- **掌握计算机视觉的核心挑战**：理解机器“看”世界与人类的不同，以及图像数据（高维、空间相关）带来的独特挑战。
- **从第一性原理理解 CNN**：深入把握卷积神经网络（CNN）通过局部感受野、参数共享和层次化特征提取来高效处理图像的核心思想。
- **初步接触 ViT**：了解视觉 Transformer（ViT）如何将 Transformer 架构成功应用于视觉领域，挑战 CNN 的主导地位。
- **实践 Vibe Coding 的图像分类工作流**：高效利用预训练的 CNN 模型完成一个图像分类任务，并学会通过分析特征图来“窥探”模型的内部工作。

## 章节结构

### 12.1 商业挑战：让机器“看见”商机

- **开篇商业挑战**：一家时尚电商公司希望通过用户上传的服装图片，自动识别服装的类别（如“T恤”、“连衣裙”、“牛仔裤”），以优化商品标签和推荐系统。
- **第一性原理**：一张图片对计算机来说，只是一个巨大的数字矩阵（`高度 x 宽度 x 颜色通道`）。计算机视觉的核心挑战在于，如何从这个原始的、高维的像素矩阵中，提取出有意义的、抽象的**特征 (Features)**，例如边缘、纹理、形状，乃至“猫的耳朵”或“汽车的轮子”。

### 12.2 卷积神经网络 (CNN)：生物启发的智慧

- **为什么不能用全连接网络？**：如果将一张 224x224 的图片直接输入一个标准的全连接神经网络，第一层就会产生数亿个参数，这在计算上是不可行的，也完全忽略了像素之间的**空间结构**。
- **CNN 的三大基石**：
    1.  **局部感受野 (Local Receptive Fields)**：每个神经元不再连接到所有输入像素，而只连接到一个小的局部区域（e.g., 3x3 或 5x5）。这模拟了生物视觉系统中神经元只对特定区域的刺激有反应。
    2.  **参数共享 (Parameter Sharing)**：一个用于检测特定特征（e.g., 水平边缘）的**滤波器 (Filter)** 或**卷积核 (Kernel)**，会在整张图片上滑动（卷积操作），共享同一套权重。这意味着，无论“水平边缘”出现在图片的哪个位置，我们都能用同一个“探测器”来找到它。这极大地减少了参数数量。
    3.  **层次化特征提取 (Hierarchical Feature Extraction)**：CNN 通常由多个卷积层堆叠而成。浅层网络学习到的是基础特征（边缘、颜色块），深层网络则将这些基础特征组合成更复杂的模式（纹理、形状），最高层则能识别出物体的部件乃至整个物体。
- **互动动画**：
    - **动画1**：可视化一个 3x3 的卷积核在输入图片上滑动的过程，展示输出的**特征图 (Feature Map)** 是如何生成的。
    - **动画2**：展示一个训练好的 CNN，输入一张图片，并逐层可视化其生成的特征图，让学生直观地看到特征是如何从简单到复杂被提取的。

### 12.3 视觉 Transformer (ViT)：一种全新的“看法”

- **CNN 的局限**：CNN 的卷积操作本质上是“局部”的，它可能难以捕捉图像中相距很远的两个部分之间的长距离依赖关系。
- **ViT 的核心思想**：
    1.  **将图片切成“词”**：ViT 首先将输入的图片分割成一系列固定大小的小块（Patches），例如 16x16 像素。
    2.  **像处理句子一样处理图片**：然后，ViT 将这些小块“拉平”成向量，并像处理句子中的词语一样，将它们输入一个标准的 Transformer 编码器。
    3.  **全局注意力**：通过 Transformer 的自注意力机制，模型中的每个小块都能“关注”到图像中的所有其他小块，从而能一步到位地捕捉全局信息。
- **（本章仅介绍核心思想，不深入细节，作为与 CNN 的对比和未来趋势的展望）**

### 12.4 Vibe Coding 实践：利用预训练模型进行图像分类

- **任务描述**：使用一个包含多种服装类别的图像数据集（如 Fashion-MNIST 或更复杂的自定义数据集）。
- **为什么需要预训练模型**：从零开始训练一个大型 CNN 需要海量的数据和计算资源。更实际的做法是使用**迁移学习**，即在一个巨大的数据集（如 ImageNet）上预训练好的模型（e.g., ResNet, VGG）的基础上进行微调。
- **第一阶段：AI 快速实现 (10分钟)**
    - **提示 (Prompt)**：“使用 PyTorch 或 TensorFlow，加载一个预训练好的 ResNet18 模型。修改其最后的分类层以适应我们的服装分类任务（N个类别）。然后，对模型进行微调（Fine-tuning）。”
- **第二阶段：人类分析与诊断 (30分钟)**
    - **引导性问题**：
        1.  **模型在“看”什么？**：我们能否可视化模型中间层的特征图，来理解它在识别“连衣裙”时，究竟是被哪些区域（e.g., 裙摆、腰线）激活的？
        2.  **模型在哪里犯错？**：找出一些模型分类错误的图片。通过观察这些图片和它们的特征图，我们能否分析出模型犯错的原因？（e.g., 是不是因为它过度关注背景？还是因为服装的样式不寻常？）
        3.  **数据增强**：为了让模型更稳健，我们可以在训练时对图片进行哪些**数据增强 (Data Augmentation)** 操作？（e.g., 随机旋转、裁剪、改变亮度）
    - **学生动手**：
        - 指导 AI 生成代码来提取并可视化特定卷积层的特征图。
        - 创建一个“错误案例集”，并撰写简短的分析报告。
        - 指导 AI 在训练流程中加入数据增强的步骤。

## 练习与作业

1.  **设计滤波器**：请你手动设计一个 3x3 的卷积核，当它与一个图像矩阵进行卷积时，能够有效地检测出图像中的“垂直边缘”。
2.  **CNN vs. ViT 讨论**：假设你的任务是识别医学影像（如 X 光片）中的微小病变。你认为 CNN 的局部性还是 ViT 的全局性在 این场景下可能更有优势？为什么？
3.  **Vibe Coding 挑战**：使用一种叫做 Grad-CAM 的技术，它可以生成一个“热力图”，高亮显示出图片中对模型最终决策贡献最大的区域。尝试指导 AI 为你实现 Grad-CAM 可视化，并用它来解释为什么模型会将一张图片识别为“T恤”。
